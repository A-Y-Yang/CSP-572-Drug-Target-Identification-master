{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing Libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, auc, f1_score, roc_curve\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Preparation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PubchemFP0</th>\n",
       "      <th>PubchemFP1</th>\n",
       "      <th>PubchemFP2</th>\n",
       "      <th>PubchemFP3</th>\n",
       "      <th>PubchemFP4</th>\n",
       "      <th>PubchemFP5</th>\n",
       "      <th>PubchemFP6</th>\n",
       "      <th>PubchemFP7</th>\n",
       "      <th>PubchemFP8</th>\n",
       "      <th>PubchemFP9</th>\n",
       "      <th>...</th>\n",
       "      <th>PubchemFP872</th>\n",
       "      <th>PubchemFP873</th>\n",
       "      <th>PubchemFP874</th>\n",
       "      <th>PubchemFP875</th>\n",
       "      <th>PubchemFP876</th>\n",
       "      <th>PubchemFP877</th>\n",
       "      <th>PubchemFP878</th>\n",
       "      <th>PubchemFP879</th>\n",
       "      <th>PubchemFP880</th>\n",
       "      <th>bioactivity_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 882 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PubchemFP0  PubchemFP1  PubchemFP2  PubchemFP3  PubchemFP4  PubchemFP5  \\\n",
       "0           1           1           0           0           0           0   \n",
       "1           1           1           0           0           0           0   \n",
       "2           1           1           0           0           0           0   \n",
       "3           1           1           0           0           0           0   \n",
       "4           1           1           0           0           0           0   \n",
       "\n",
       "   PubchemFP6  PubchemFP7  PubchemFP8  PubchemFP9  ...  PubchemFP872  \\\n",
       "0           0           0           0           1  ...             0   \n",
       "1           0           0           0           1  ...             0   \n",
       "2           0           0           0           1  ...             0   \n",
       "3           0           0           0           1  ...             0   \n",
       "4           0           0           0           1  ...             0   \n",
       "\n",
       "   PubchemFP873  PubchemFP874  PubchemFP875  PubchemFP876  PubchemFP877  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   PubchemFP878  PubchemFP879  PubchemFP880  bioactivity_class  \n",
       "0             0             0             0             active  \n",
       "1             0             0             0             active  \n",
       "2             0             0             0             active  \n",
       "3             0             0             0             active  \n",
       "4             0             0             0             active  \n",
       "\n",
       "[5 rows x 882 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file.\n",
    "df = pd.read_csv('CHEMBL203_EGFR_2class_pubchem_fp.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Cleaning</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PubchemFP0            int64\n",
      "PubchemFP1            int64\n",
      "PubchemFP2            int64\n",
      "PubchemFP3            int64\n",
      "PubchemFP4            int64\n",
      "                      ...  \n",
      "PubchemFP877          int64\n",
      "PubchemFP878          int64\n",
      "PubchemFP879          int64\n",
      "PubchemFP880          int64\n",
      "bioactivity_class    object\n",
      "Length: 882, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubchemFP0           0\n",
       "PubchemFP1           0\n",
       "PubchemFP2           0\n",
       "PubchemFP3           0\n",
       "PubchemFP4           0\n",
       "                    ..\n",
       "PubchemFP877         0\n",
       "PubchemFP878         0\n",
       "PubchemFP879         0\n",
       "PubchemFP880         0\n",
       "bioactivity_class    0\n",
       "Length: 882, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PubchemFP0           0\n",
       "PubchemFP1           0\n",
       "PubchemFP2           0\n",
       "PubchemFP3           0\n",
       "PubchemFP4           0\n",
       "                    ..\n",
       "PubchemFP877         0\n",
       "PubchemFP878         0\n",
       "PubchemFP879         0\n",
       "PubchemFP880         0\n",
       "bioactivity_class    0\n",
       "Length: 882, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2377, 882)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "active      1191\n",
       "inactive    1186\n",
       "Name: bioactivity_class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bioactivity_class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>inactive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2377 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      active  inactive\n",
       "0          1         0\n",
       "1          1         0\n",
       "2          1         0\n",
       "3          1         0\n",
       "4          1         0\n",
       "...      ...       ...\n",
       "2372       0         1\n",
       "2373       0         1\n",
       "2374       0         1\n",
       "2375       0         1\n",
       "2376       0         1\n",
       "\n",
       "[2377 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(df['bioactivity_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "x = df.iloc[:,:881]\n",
    "y = pd.get_dummies(df['bioactivity_class'])['active']\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "881"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Modeling</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "# Hyper-tunning the 'criterion', 'max_depth', 'min_sample_leaf' and 'min_sample_split' parameter\n",
    "values = [i for i in range(1, 21)]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for i in range(1,21):\n",
    "    model = DecisionTreeClassifier(max_depth=i, criterion = 'entropy', random_state=25)\n",
    "    # fit model on the training dataset\n",
    "    model.fit(x_train, y_train)\n",
    "    # evaluate on the train dataset\n",
    "    train_yhat = model.predict(x_train)\n",
    "    train_acc = accuracy_score(y_train, train_yhat)\n",
    "    train_scores.append(train_acc)\n",
    "    # evaluate on the test dataset\n",
    "    test_yhat = model.predict(x_test)\n",
    "    test_acc = accuracy_score(y_test, test_yhat)\n",
    "    test_scores.append(test_acc)\n",
    "    # summarize progress\n",
    "    print('>%d, train: %.3f, test: %.3f' % (i, train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10, 110, 10):\n",
    "    clf = DecisionTreeClassifier(criterion='gini', max_depth=10)\n",
    "    clf.fit(x_train, y_train)\n",
    "    pred = clf.predict(x_test)\n",
    "    dt_acc = accuracy_score(y_test, pred)\n",
    "    print(i, dt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# Hyper-tunning the 'n_neighbors' parameter\n",
    "neighbors = list(range(1,21,1))\n",
    "knn_accuracy_test = []\n",
    "knn_accuracy_train = []\n",
    "knn_df = pd.DataFrame(columns=['n_neighbors', 'test_Accuracy', 'train_accuracy'])\n",
    "for i in neighbors:\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_clf.fit(x_train, y_train)\n",
    "    knn_pred = knn_clf.predict(x_test)\n",
    "    knn_acc = accuracy_score(y_test, knn_pred)\n",
    "    knn_accuracy_test.append(knn_acc)\n",
    "    knn_pred = knn_clf.predict(x_train)\n",
    "    knn_acc = accuracy_score(y_train, knn_pred)\n",
    "    knn_accuracy_train.append(knn_acc)\n",
    "    \n",
    "knn_df['n_neighbors'] = neighbors\n",
    "knn_df['test_Accuracy'] = knn_accuracy_test\n",
    "knn_df['train_accuracy'] = knn_accuracy_train\n",
    "knn_df['difference'] = abs(knn_df['test_Accuracy'].values - knn_df['train_accuracy'].values)\n",
    "k_best, k_accu_best = knn_df.sort_values(['difference', 'test_Accuracy'], ascending=[True, False]).head(1)[['n_neighbors', 'test_Accuracy']].values[0]\n",
    "print(\"Best Parameter for KNN, k =\", k_best)\n",
    "plt.plot(neighbors, knn_accuracy_test, label='test data', marker='o')\n",
    "plt.plot(neighbors, knn_accuracy_train, label='train data', marker='o')\n",
    "plt.plot(k_best, k_accu_best, marker='o', color='red')\n",
    "plt.grid() \n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"For K-Nearest Neighbors\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "knn_pred = knn_clf.predict(x_test)\n",
    "knn_acc = accuracy_score(y_test, knn_pred)\n",
    "knn_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Classifier(SVC)\n",
    "from sklearn.svm import SVC\n",
    "# Hyper-tunning the 'kernel' and 'gamma' parameter\n",
    "svc_dict = {'auto': ['linear'], 'scale': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "svc_accuracy_test = []\n",
    "svc_accuracy_train = []\n",
    "svc_df = pd.DataFrame(columns=['Parameters', 'test_Accuracy', 'train_Accuracy'])\n",
    "parameter = []\n",
    "cnt = []\n",
    "count = 0\n",
    "for i in svc_dict:\n",
    "    for j in svc_dict[i]:\n",
    "        count+=1\n",
    "        svc_clf = SVC(kernel=j, gamma=i, random_state=100)\n",
    "        svc_clf.fit(x_train, y_train)\n",
    "        svc_pred = svc_clf.predict(x_test)\n",
    "        svc_acc = accuracy_score(y_test, svc_pred)\n",
    "        svc_accuracy_test.append(svc_acc)\n",
    "        svc_pred = svc_clf.predict(x_train)\n",
    "        svc_acc = accuracy_score(y_train, svc_pred)\n",
    "        svc_accuracy_train.append(svc_acc)\n",
    "        cnt.append(count)\n",
    "        para = '[kernel = '+str(i)+', gamma = '+str(j)+']'\n",
    "        parameter.append(para)\n",
    "svc_df['Parameters'] = parameter\n",
    "svc_df['test_Accuracy'] = svc_accuracy_test\n",
    "svc_df['train_Accuracy'] = svc_accuracy_train\n",
    "svc_df['difference'] = abs(svc_df['test_Accuracy'] - svc_df['train_Accuracy'])\n",
    "svc_df[\"count\"] = cnt\n",
    "\n",
    "svc_best, svc_accu_best, best_para = svc_df.sort_values(['difference', 'test_Accuracy'], ascending=[True, False]).head(1)[['count', 'test_Accuracy', 'Parameters']].values[0]\n",
    "print('Best Parameter for Support Vector Machine(SVC) = ', best_para)\n",
    "plt.plot(cnt, svc_accuracy_test, label='test_data', marker ='o')\n",
    "plt.plot(cnt, svc_accuracy_train, label='train_data', marker='o')\n",
    "plt.plot(svc_best, svc_accu_best, marker='o', color='red')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Various Parameters\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"For SVC\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"dt.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open(\"dt.pkl\", \"rb\") as file:\n",
    "#     pickle.dump(clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Hyper-tunning the 'penalty' and 'solver' parameter\n",
    "lr_dict = {'l1': ['liblinear', 'saga'], 'l2': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']}\n",
    "lr_accuracy_test = []\n",
    "lr_accuracy_train = []\n",
    "lr_accuracy_cv = []\n",
    "lr_df = pd.DataFrame(columns=['Parameters', 'test_Accuracy', 'train_Accuracy'])\n",
    "parameter = []\n",
    "cnt = []\n",
    "count = 0\n",
    "for i in lr_dict:\n",
    "    for j in lr_dict[i]:\n",
    "        count+=1\n",
    "        lr_clf = LogisticRegression(penalty=i, solver=j, random_state=120)\n",
    "        lr_clf.fit(x_train, y_train)\n",
    "        lr_pred = lr_clf.predict(x_test)\n",
    "        lr_acc = accuracy_score(y_test, lr_pred)\n",
    "        lr_accuracy_test.append(lr_acc)\n",
    "        lr_pred = lr_clf.predict(x_train)\n",
    "        lr_acc = accuracy_score(y_train, lr_pred)\n",
    "        lr_accuracy_train.append(lr_acc)\n",
    "        cnt.append(count)\n",
    "        para = '[penalty = '+str(i)+', solver = '+str(j)+']'\n",
    "        parameter.append(para)\n",
    "\n",
    "lr_df['Parameters'] = parameter\n",
    "lr_df['test_Accuracy'] = lr_accuracy_test\n",
    "lr_df['train_Accuracy'] = lr_accuracy_train\n",
    "lr_df['difference'] = abs(lr_df['test_Accuracy'] - lr_df['train_Accuracy'])\n",
    "lr_df[\"count\"] = cnt\n",
    "\n",
    "lr_best, lr_accu_best, best_para = lr_df.sort_values(['difference', 'test_Accuracy'], ascending=[True, False]).head(1)[['count', 'test_Accuracy', 'Parameters']].values[0]\n",
    "print('Best Parameters for Logistic Regression =', best_para)\n",
    "plt.plot(cnt, lr_accuracy_test, label='test_data', marker ='o')\n",
    "plt.plot(cnt, lr_accuracy_train, label='train_data', marker='o')\n",
    "plt.plot(lr_best, lr_accu_best, marker='o', color='red')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Various Parameters\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"For Logistic Regression\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBooster Classifier\n",
    "# from xgboost import XGBClassifier\n",
    "# clf = XGBClassifier()\n",
    "# clf.fit(x_train, y_train)\n",
    "# pred = clf.predict(x_test)\n",
    "# print(\"Accuracy for XGBooster:\",accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix from Random-Forest Classifier\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "print(\"Accuracy for Random-Forest:\",accuracy_score(y_test, pred))\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf_matrix = confusion_matrix(y_test, pred)\n",
    "group_names = ['True Pos', 'False Neg', 'False Pos', 'True Neg']\n",
    "group_counts = cf_matrix.flatten()\n",
    "group_percentages = np.round(cf_matrix.flatten()/sum(cf_matrix.flatten()), 2)\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "\n",
    "\n",
    "# group_names = ['True Pos', 'False Neg', 'False Pos', 'True Neg']\n",
    "sns.heatmap(cf_matrix, annot =True,cmap='Blues', fmt='')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=150, verbose=0, mode='auto',\n",
    "    baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001), input_shape=[len(x_train.keys())]),\n",
    "    layers.Dense(64, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(16, activation='tanh', kernel_regularizer=keras.regularizers.l2(0.001)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.001))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 1.0137 - accuracy: 0.5605 - val_loss: 0.8669 - val_accuracy: 0.7192\n",
      "Epoch 2/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.8607 - accuracy: 0.6487 - val_loss: 0.7178 - val_accuracy: 0.7874\n",
      "Epoch 3/500\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.7574 - accuracy: 0.72 - 0s 5ms/step - loss: 0.7605 - accuracy: 0.7270 - val_loss: 0.6400 - val_accuracy: 0.8136\n",
      "Epoch 4/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.6635 - accuracy: 0.7914 - val_loss: 0.5997 - val_accuracy: 0.8425\n",
      "Epoch 5/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.5884 - accuracy: 0.8408 - val_loss: 0.5784 - val_accuracy: 0.8320\n",
      "Epoch 6/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.5396 - accuracy: 0.8592 - val_loss: 0.5408 - val_accuracy: 0.8688\n",
      "Epoch 7/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.5032 - accuracy: 0.8717 - val_loss: 0.5572 - val_accuracy: 0.8478\n",
      "Epoch 8/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.4884 - accuracy: 0.8993 - val_loss: 0.5734 - val_accuracy: 0.8425\n",
      "Epoch 9/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.8908 - val_loss: 0.6099 - val_accuracy: 0.8504\n",
      "Epoch 10/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8961 - val_loss: 0.5538 - val_accuracy: 0.8399\n",
      "Epoch 11/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4209 - accuracy: 0.8987 - val_loss: 0.5555 - val_accuracy: 0.8609\n",
      "Epoch 12/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8921 - val_loss: 0.4863 - val_accuracy: 0.8793\n",
      "Epoch 13/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.3791 - accuracy: 0.9237 - val_loss: 0.5017 - val_accuracy: 0.8793\n",
      "Epoch 14/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.9250 - val_loss: 0.5300 - val_accuracy: 0.8346\n",
      "Epoch 15/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.3368 - accuracy: 0.9336 - val_loss: 0.5537 - val_accuracy: 0.8556\n",
      "Epoch 16/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.3381 - accuracy: 0.9316 - val_loss: 0.4935 - val_accuracy: 0.8688\n",
      "Epoch 17/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.3050 - accuracy: 0.9395 - val_loss: 0.5585 - val_accuracy: 0.8766\n",
      "Epoch 18/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.3087 - accuracy: 0.9401 - val_loss: 0.4618 - val_accuracy: 0.8845\n",
      "Epoch 19/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2901 - accuracy: 0.9467 - val_loss: 0.4904 - val_accuracy: 0.8714\n",
      "Epoch 20/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.2946 - accuracy: 0.9421 - val_loss: 0.4750 - val_accuracy: 0.8871\n",
      "Epoch 21/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.9546 - val_loss: 0.4844 - val_accuracy: 0.8688\n",
      "Epoch 22/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.2416 - accuracy: 0.9579 - val_loss: 0.4655 - val_accuracy: 0.8819\n",
      "Epoch 23/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.2446 - accuracy: 0.9579 - val_loss: 0.6012 - val_accuracy: 0.8661\n",
      "Epoch 24/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.2480 - accuracy: 0.9520 - val_loss: 0.5034 - val_accuracy: 0.8793\n",
      "Epoch 25/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.2273 - accuracy: 0.9599 - val_loss: 0.5684 - val_accuracy: 0.8661\n",
      "Epoch 26/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.2158 - accuracy: 0.9671 - val_loss: 0.5137 - val_accuracy: 0.8714\n",
      "Epoch 27/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.2216 - accuracy: 0.9605 - val_loss: 0.5318 - val_accuracy: 0.8819\n",
      "Epoch 28/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.2018 - accuracy: 0.9697 - val_loss: 0.5175 - val_accuracy: 0.8609\n",
      "Epoch 29/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1946 - accuracy: 0.9697 - val_loss: 0.4679 - val_accuracy: 0.9029\n",
      "Epoch 30/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1940 - accuracy: 0.9678 - val_loss: 0.4858 - val_accuracy: 0.8898\n",
      "Epoch 31/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1907 - accuracy: 0.9704 - val_loss: 0.5314 - val_accuracy: 0.8793\n",
      "Epoch 32/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1846 - accuracy: 0.9711 - val_loss: 0.5091 - val_accuracy: 0.9003\n",
      "Epoch 33/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1584 - accuracy: 0.9829 - val_loss: 0.4813 - val_accuracy: 0.9003\n",
      "Epoch 34/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1628 - accuracy: 0.9783 - val_loss: 0.4930 - val_accuracy: 0.9055\n",
      "Epoch 35/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.9717 - val_loss: 0.4783 - val_accuracy: 0.9029\n",
      "Epoch 36/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1946 - accuracy: 0.9658 - val_loss: 0.4971 - val_accuracy: 0.8950\n",
      "Epoch 37/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9743 - val_loss: 0.4745 - val_accuracy: 0.8845\n",
      "Epoch 38/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9776 - val_loss: 0.5075 - val_accuracy: 0.8976\n",
      "Epoch 39/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1643 - accuracy: 0.9711 - val_loss: 0.4851 - val_accuracy: 0.9081\n",
      "Epoch 40/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9882 - val_loss: 0.5822 - val_accuracy: 0.8845\n",
      "Epoch 41/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1384 - accuracy: 0.9849 - val_loss: 0.5546 - val_accuracy: 0.9055\n",
      "Epoch 42/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.2164 - accuracy: 0.9553 - val_loss: 0.5259 - val_accuracy: 0.8688\n",
      "Epoch 43/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.9776 - val_loss: 0.5077 - val_accuracy: 0.8898\n",
      "Epoch 44/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.9691 - val_loss: 0.5412 - val_accuracy: 0.8819\n",
      "Epoch 45/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9822 - val_loss: 0.5008 - val_accuracy: 0.8950\n",
      "Epoch 46/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.9651 - val_loss: 0.4602 - val_accuracy: 0.9055\n",
      "Epoch 47/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9862 - val_loss: 0.4929 - val_accuracy: 0.8898\n",
      "Epoch 48/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1424 - accuracy: 0.9796 - val_loss: 0.5962 - val_accuracy: 0.8688\n",
      "Epoch 49/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1584 - accuracy: 0.9743 - val_loss: 0.4368 - val_accuracy: 0.9003\n",
      "Epoch 50/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1249 - accuracy: 0.9882 - val_loss: 0.5075 - val_accuracy: 0.8898\n",
      "Epoch 51/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1430 - accuracy: 0.9789 - val_loss: 0.5057 - val_accuracy: 0.9055\n",
      "Epoch 52/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9836 - val_loss: 0.5708 - val_accuracy: 0.8845\n",
      "Epoch 53/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1450 - accuracy: 0.9776 - val_loss: 0.5500 - val_accuracy: 0.8898\n",
      "Epoch 54/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1201 - accuracy: 0.9888 - val_loss: 0.6029 - val_accuracy: 0.8924\n",
      "Epoch 55/500\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.1165 - accuracy: 0.9888 - val_loss: 0.5642 - val_accuracy: 0.9081\n",
      "Epoch 56/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1406 - accuracy: 0.9809 - val_loss: 0.5752 - val_accuracy: 0.8950\n",
      "Epoch 57/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9855 - val_loss: 0.5527 - val_accuracy: 0.9029\n",
      "Epoch 58/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1140 - accuracy: 0.9888 - val_loss: 0.5038 - val_accuracy: 0.9081\n",
      "Epoch 59/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1101 - accuracy: 0.9888 - val_loss: 0.5676 - val_accuracy: 0.8950\n",
      "Epoch 60/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1192 - accuracy: 0.9868 - val_loss: 0.5065 - val_accuracy: 0.9134\n",
      "Epoch 61/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1421 - accuracy: 0.9776 - val_loss: 0.5839 - val_accuracy: 0.8661\n",
      "Epoch 62/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1385 - accuracy: 0.9783 - val_loss: 0.4955 - val_accuracy: 0.9134\n",
      "Epoch 63/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1193 - accuracy: 0.9855 - val_loss: 0.5327 - val_accuracy: 0.8950\n",
      "Epoch 64/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9842 - val_loss: 0.5084 - val_accuracy: 0.9055\n",
      "Epoch 65/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9888 - val_loss: 0.5154 - val_accuracy: 0.9055\n",
      "Epoch 66/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1164 - accuracy: 0.9829 - val_loss: 0.5215 - val_accuracy: 0.9081\n",
      "Epoch 67/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1409 - accuracy: 0.9763 - val_loss: 0.5437 - val_accuracy: 0.8924\n",
      "Epoch 68/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1311 - accuracy: 0.9809 - val_loss: 0.4859 - val_accuracy: 0.8924\n",
      "Epoch 69/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1244 - accuracy: 0.9829 - val_loss: 0.4932 - val_accuracy: 0.9108\n",
      "Epoch 70/500\n",
      "48/48 [==============================] - 1s 10ms/step - loss: 0.1574 - accuracy: 0.9704 - val_loss: 0.4765 - val_accuracy: 0.9029\n",
      "Epoch 71/500\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.1350 - accuracy: 0.9803 - val_loss: 0.4728 - val_accuracy: 0.9055\n",
      "Epoch 72/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1088 - accuracy: 0.9862 - val_loss: 0.5935 - val_accuracy: 0.8950\n",
      "Epoch 73/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1495 - accuracy: 0.9711 - val_loss: 0.6439 - val_accuracy: 0.8504\n",
      "Epoch 74/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1426 - accuracy: 0.9763 - val_loss: 0.5563 - val_accuracy: 0.8950\n",
      "Epoch 75/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1239 - accuracy: 0.9842 - val_loss: 0.4807 - val_accuracy: 0.8950\n",
      "Epoch 76/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1224 - accuracy: 0.9796 - val_loss: 0.6608 - val_accuracy: 0.8714\n",
      "Epoch 77/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9934 - val_loss: 0.5272 - val_accuracy: 0.9055\n",
      "Epoch 78/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0974 - accuracy: 0.9928 - val_loss: 0.5217 - val_accuracy: 0.9081\n",
      "Epoch 79/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0932 - accuracy: 0.9934 - val_loss: 0.4948 - val_accuracy: 0.9186\n",
      "Epoch 80/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0923 - accuracy: 0.9934 - val_loss: 0.5052 - val_accuracy: 0.9134\n",
      "Epoch 81/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1062 - accuracy: 0.9868 - val_loss: 0.4581 - val_accuracy: 0.9186\n",
      "Epoch 82/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1043 - accuracy: 0.9868 - val_loss: 0.6187 - val_accuracy: 0.8871\n",
      "Epoch 83/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1052 - accuracy: 0.9868 - val_loss: 0.4570 - val_accuracy: 0.9186\n",
      "Epoch 84/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0886 - accuracy: 0.9947 - val_loss: 0.5362 - val_accuracy: 0.9081\n",
      "Epoch 85/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9934 - val_loss: 0.5771 - val_accuracy: 0.8950\n",
      "Epoch 86/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1296 - accuracy: 0.9763 - val_loss: 0.5381 - val_accuracy: 0.8871\n",
      "Epoch 87/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1041 - accuracy: 0.9875 - val_loss: 0.4268 - val_accuracy: 0.9265\n",
      "Epoch 88/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.0971 - accuracy: 0.9908 - val_loss: 0.5045 - val_accuracy: 0.9081\n",
      "Epoch 89/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1062 - accuracy: 0.9875 - val_loss: 0.5543 - val_accuracy: 0.9055\n",
      "Epoch 90/500\n",
      "48/48 [==============================] - 0s 8ms/step - loss: 0.1274 - accuracy: 0.9776 - val_loss: 0.5011 - val_accuracy: 0.8976\n",
      "Epoch 91/500\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.0928 - accuracy: 0.9934 - val_loss: 0.5215 - val_accuracy: 0.9160\n",
      "Epoch 92/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0967 - accuracy: 0.9914 - val_loss: 0.5033 - val_accuracy: 0.9186\n",
      "Epoch 93/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1248 - accuracy: 0.9816 - val_loss: 0.6027 - val_accuracy: 0.8793\n",
      "Epoch 94/500\n",
      "48/48 [==============================] - 0s 10ms/step - loss: 0.0959 - accuracy: 0.9895 - val_loss: 0.4884 - val_accuracy: 0.9160\n",
      "Epoch 95/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0950 - accuracy: 0.9895 - val_loss: 0.5903 - val_accuracy: 0.8898\n",
      "Epoch 96/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1133 - accuracy: 0.9849 - val_loss: 0.5340 - val_accuracy: 0.9108\n",
      "Epoch 97/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1760 - accuracy: 0.9651 - val_loss: 0.5393 - val_accuracy: 0.8898\n",
      "Epoch 98/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1193 - accuracy: 0.9816 - val_loss: 0.4143 - val_accuracy: 0.9160\n",
      "Epoch 99/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9928 - val_loss: 0.4648 - val_accuracy: 0.9318\n",
      "Epoch 100/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0893 - accuracy: 0.9941 - val_loss: 0.5124 - val_accuracy: 0.9029\n",
      "Epoch 101/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1515 - accuracy: 0.9671 - val_loss: 0.5073 - val_accuracy: 0.8766\n",
      "Epoch 102/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1328 - accuracy: 0.9776 - val_loss: 0.5077 - val_accuracy: 0.9108\n",
      "Epoch 103/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9855 - val_loss: 0.5178 - val_accuracy: 0.8976\n",
      "Epoch 104/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.1000 - accuracy: 0.9914 - val_loss: 0.5341 - val_accuracy: 0.9003\n",
      "Epoch 105/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9901 - val_loss: 0.5456 - val_accuracy: 0.9081\n",
      "Epoch 106/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9901 - val_loss: 0.5797 - val_accuracy: 0.9108\n",
      "Epoch 107/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9895 - val_loss: 0.4871 - val_accuracy: 0.9134\n",
      "Epoch 108/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9882 - val_loss: 0.5007 - val_accuracy: 0.9081\n",
      "Epoch 109/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9862 - val_loss: 0.4985 - val_accuracy: 0.9108\n",
      "Epoch 110/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0945 - accuracy: 0.9901 - val_loss: 0.6035 - val_accuracy: 0.8924\n",
      "Epoch 111/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0961 - accuracy: 0.9914 - val_loss: 0.4779 - val_accuracy: 0.9186\n",
      "Epoch 112/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9961 - val_loss: 0.5119 - val_accuracy: 0.9160\n",
      "Epoch 113/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9928 - val_loss: 0.5351 - val_accuracy: 0.9081\n",
      "Epoch 114/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9914 - val_loss: 0.5298 - val_accuracy: 0.9108\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9947 - val_loss: 0.5468 - val_accuracy: 0.9160\n",
      "Epoch 116/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0851 - accuracy: 0.9934 - val_loss: 0.5530 - val_accuracy: 0.9134\n",
      "Epoch 117/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9888 - val_loss: 0.6111 - val_accuracy: 0.8793\n",
      "Epoch 118/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9855 - val_loss: 0.6541 - val_accuracy: 0.8976\n",
      "Epoch 119/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1074 - accuracy: 0.9842 - val_loss: 0.7618 - val_accuracy: 0.8530\n",
      "Epoch 120/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0987 - accuracy: 0.9895 - val_loss: 0.5393 - val_accuracy: 0.8924\n",
      "Epoch 121/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0894 - accuracy: 0.9921 - val_loss: 0.5280 - val_accuracy: 0.9134\n",
      "Epoch 122/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1020 - accuracy: 0.9868 - val_loss: 0.5675 - val_accuracy: 0.9029\n",
      "Epoch 123/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1121 - accuracy: 0.9829 - val_loss: 0.5324 - val_accuracy: 0.9108\n",
      "Epoch 124/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0888 - accuracy: 0.9941 - val_loss: 0.4980 - val_accuracy: 0.9160\n",
      "Epoch 125/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9980 - val_loss: 0.5149 - val_accuracy: 0.9186\n",
      "Epoch 126/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9954 - val_loss: 0.5756 - val_accuracy: 0.9160\n",
      "Epoch 127/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9914 - val_loss: 0.5806 - val_accuracy: 0.9186\n",
      "Epoch 128/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9928 - val_loss: 0.5321 - val_accuracy: 0.9003\n",
      "Epoch 129/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9901 - val_loss: 0.6026 - val_accuracy: 0.8950\n",
      "Epoch 130/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9921 - val_loss: 0.6350 - val_accuracy: 0.8845\n",
      "Epoch 131/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9862 - val_loss: 0.4642 - val_accuracy: 0.9213\n",
      "Epoch 132/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1051 - accuracy: 0.9882 - val_loss: 0.5706 - val_accuracy: 0.9003\n",
      "Epoch 133/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9921 - val_loss: 0.4845 - val_accuracy: 0.9213\n",
      "Epoch 134/500\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 0.0783 - accuracy: 0.9967 - val_loss: 0.6291 - val_accuracy: 0.9108\n",
      "Epoch 135/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9901 - val_loss: 0.5480 - val_accuracy: 0.9108\n",
      "Epoch 136/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9928 - val_loss: 0.5407 - val_accuracy: 0.9108\n",
      "Epoch 137/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0982 - accuracy: 0.9895 - val_loss: 0.5617 - val_accuracy: 0.9003\n",
      "Epoch 138/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9947 - val_loss: 0.5768 - val_accuracy: 0.9160\n",
      "Epoch 139/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9914 - val_loss: 0.5465 - val_accuracy: 0.9108\n",
      "Epoch 140/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9829 - val_loss: 0.5459 - val_accuracy: 0.9003\n",
      "Epoch 141/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1139 - accuracy: 0.9842 - val_loss: 0.5809 - val_accuracy: 0.8950\n",
      "Epoch 142/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9934 - val_loss: 0.5507 - val_accuracy: 0.9081\n",
      "Epoch 143/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0870 - accuracy: 0.9882 - val_loss: 0.5383 - val_accuracy: 0.9160\n",
      "Epoch 144/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9895 - val_loss: 0.5081 - val_accuracy: 0.9213\n",
      "Epoch 145/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9967 - val_loss: 0.6062 - val_accuracy: 0.8924\n",
      "Epoch 146/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0885 - accuracy: 0.9914 - val_loss: 0.5302 - val_accuracy: 0.9108\n",
      "Epoch 147/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0762 - accuracy: 0.9980 - val_loss: 0.5701 - val_accuracy: 0.9134\n",
      "Epoch 148/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9638 - val_loss: 0.4091 - val_accuracy: 0.9186\n",
      "Epoch 149/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9941 - val_loss: 0.4864 - val_accuracy: 0.9160\n",
      "Epoch 150/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0935 - accuracy: 0.9901 - val_loss: 0.5104 - val_accuracy: 0.9029\n",
      "Epoch 151/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9717 - val_loss: 0.5370 - val_accuracy: 0.8819\n",
      "Epoch 152/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1237 - accuracy: 0.9763 - val_loss: 0.4847 - val_accuracy: 0.9134\n",
      "Epoch 153/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9928 - val_loss: 0.4791 - val_accuracy: 0.9213\n",
      "Epoch 154/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0794 - accuracy: 0.9954 - val_loss: 0.5620 - val_accuracy: 0.8950\n",
      "Epoch 155/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9947 - val_loss: 0.5367 - val_accuracy: 0.9213\n",
      "Epoch 156/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9947 - val_loss: 0.5964 - val_accuracy: 0.9081\n",
      "Epoch 157/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 0.9941 - val_loss: 0.5579 - val_accuracy: 0.9003\n",
      "Epoch 158/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0786 - accuracy: 0.9961 - val_loss: 0.5792 - val_accuracy: 0.9108\n",
      "Epoch 159/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0752 - accuracy: 0.9954 - val_loss: 0.6130 - val_accuracy: 0.9055\n",
      "Epoch 160/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9941 - val_loss: 0.5169 - val_accuracy: 0.9108\n",
      "Epoch 161/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9941 - val_loss: 0.6464 - val_accuracy: 0.8950\n",
      "Epoch 162/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0702 - accuracy: 0.9974 - val_loss: 0.5684 - val_accuracy: 0.9081\n",
      "Epoch 163/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9954 - val_loss: 0.5633 - val_accuracy: 0.9134\n",
      "Epoch 164/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9928 - val_loss: 0.8354 - val_accuracy: 0.8530\n",
      "Epoch 165/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0946 - accuracy: 0.9908 - val_loss: 0.5231 - val_accuracy: 0.9108\n",
      "Epoch 166/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0898 - accuracy: 0.9914 - val_loss: 0.8488 - val_accuracy: 0.8399\n",
      "Epoch 167/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1287 - accuracy: 0.9783 - val_loss: 0.4799 - val_accuracy: 0.9055\n",
      "Epoch 168/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9908 - val_loss: 0.4824 - val_accuracy: 0.9134\n",
      "Epoch 169/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9901 - val_loss: 0.5666 - val_accuracy: 0.8924\n",
      "Epoch 170/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0873 - accuracy: 0.9908 - val_loss: 0.6133 - val_accuracy: 0.8976\n",
      "Epoch 171/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0708 - accuracy: 0.9987 - val_loss: 0.5566 - val_accuracy: 0.9108\n",
      "Epoch 172/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0792 - accuracy: 0.9947 - val_loss: 0.5606 - val_accuracy: 0.9108\n",
      "Epoch 173/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9914 - val_loss: 0.7045 - val_accuracy: 0.8845\n",
      "Epoch 174/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0870 - accuracy: 0.9888 - val_loss: 0.5335 - val_accuracy: 0.9160\n",
      "Epoch 175/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0916 - accuracy: 0.9901 - val_loss: 0.5767 - val_accuracy: 0.9055\n",
      "Epoch 176/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0840 - accuracy: 0.9914 - val_loss: 0.5313 - val_accuracy: 0.9081\n",
      "Epoch 177/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9974 - val_loss: 0.5994 - val_accuracy: 0.9108\n",
      "Epoch 178/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0955 - accuracy: 0.9868 - val_loss: 0.6870 - val_accuracy: 0.8583\n",
      "Epoch 179/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.9882 - val_loss: 0.5857 - val_accuracy: 0.8924\n",
      "Epoch 180/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0895 - accuracy: 0.9908 - val_loss: 0.4946 - val_accuracy: 0.9134\n",
      "Epoch 181/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9941 - val_loss: 0.5360 - val_accuracy: 0.9160\n",
      "Epoch 182/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0908 - accuracy: 0.9908 - val_loss: 0.5886 - val_accuracy: 0.8898\n",
      "Epoch 183/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0872 - accuracy: 0.9908 - val_loss: 0.4859 - val_accuracy: 0.9239\n",
      "Epoch 184/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1093 - accuracy: 0.9895 - val_loss: 0.5268 - val_accuracy: 0.8950\n",
      "Epoch 185/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0867 - accuracy: 0.9934 - val_loss: 0.5606 - val_accuracy: 0.9108\n",
      "Epoch 186/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0704 - accuracy: 0.9980 - val_loss: 0.5015 - val_accuracy: 0.9239\n",
      "Epoch 187/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0833 - accuracy: 0.9941 - val_loss: 0.6014 - val_accuracy: 0.8924\n",
      "Epoch 188/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1343 - accuracy: 0.9704 - val_loss: 0.4486 - val_accuracy: 0.9213\n",
      "Epoch 189/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9882 - val_loss: 0.4978 - val_accuracy: 0.8950\n",
      "Epoch 190/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0976 - accuracy: 0.9849 - val_loss: 0.4840 - val_accuracy: 0.9134\n",
      "Epoch 191/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1029 - accuracy: 0.9862 - val_loss: 0.4801 - val_accuracy: 0.9081\n",
      "Epoch 192/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9908 - val_loss: 0.5271 - val_accuracy: 0.9081\n",
      "Epoch 193/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9914 - val_loss: 0.5429 - val_accuracy: 0.9186\n",
      "Epoch 194/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0923 - accuracy: 0.9914 - val_loss: 0.5630 - val_accuracy: 0.9186\n",
      "Epoch 195/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9934 - val_loss: 0.5559 - val_accuracy: 0.9029\n",
      "Epoch 196/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0735 - accuracy: 0.9974 - val_loss: 0.5820 - val_accuracy: 0.8976\n",
      "Epoch 197/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0819 - accuracy: 0.9947 - val_loss: 0.5857 - val_accuracy: 0.9108\n",
      "Epoch 198/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0799 - accuracy: 0.9954 - val_loss: 0.5529 - val_accuracy: 0.9160\n",
      "Epoch 199/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9954 - val_loss: 0.5693 - val_accuracy: 0.9108\n",
      "Epoch 200/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1013 - accuracy: 0.9888 - val_loss: 0.7318 - val_accuracy: 0.8688\n",
      "Epoch 201/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1080 - accuracy: 0.9882 - val_loss: 0.5469 - val_accuracy: 0.8924\n",
      "Epoch 202/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9921 - val_loss: 0.5778 - val_accuracy: 0.8950\n",
      "Epoch 203/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9921 - val_loss: 0.5189 - val_accuracy: 0.9186\n",
      "Epoch 204/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0921 - accuracy: 0.9921 - val_loss: 0.5417 - val_accuracy: 0.8871\n",
      "Epoch 205/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0922 - accuracy: 0.9901 - val_loss: 0.6246 - val_accuracy: 0.8688\n",
      "Epoch 206/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9947 - val_loss: 0.5916 - val_accuracy: 0.8898\n",
      "Epoch 207/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9941 - val_loss: 0.6300 - val_accuracy: 0.8819\n",
      "Epoch 208/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0883 - accuracy: 0.9921 - val_loss: 0.5347 - val_accuracy: 0.9160\n",
      "Epoch 209/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9914 - val_loss: 0.5418 - val_accuracy: 0.9160\n",
      "Epoch 210/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0890 - accuracy: 0.9921 - val_loss: 0.5736 - val_accuracy: 0.9160\n",
      "Epoch 211/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0764 - accuracy: 0.9954 - val_loss: 0.5956 - val_accuracy: 0.9055\n",
      "Epoch 212/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0725 - accuracy: 0.9967 - val_loss: 0.6741 - val_accuracy: 0.8871\n",
      "Epoch 213/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9888 - val_loss: 0.6738 - val_accuracy: 0.8845\n",
      "Epoch 214/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0913 - accuracy: 0.9888 - val_loss: 0.4969 - val_accuracy: 0.9108\n",
      "Epoch 215/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9928 - val_loss: 0.5348 - val_accuracy: 0.9081\n",
      "Epoch 216/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0747 - accuracy: 0.9967 - val_loss: 0.5629 - val_accuracy: 0.8976\n",
      "Epoch 217/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9934 - val_loss: 0.5355 - val_accuracy: 0.9108\n",
      "Epoch 218/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 0.9928 - val_loss: 0.5644 - val_accuracy: 0.9081\n",
      "Epoch 219/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9895 - val_loss: 0.6141 - val_accuracy: 0.9029\n",
      "Epoch 220/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9822 - val_loss: 0.5458 - val_accuracy: 0.9029\n",
      "Epoch 221/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0835 - accuracy: 0.9921 - val_loss: 0.5395 - val_accuracy: 0.9003\n",
      "Epoch 222/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0837 - accuracy: 0.9941 - val_loss: 0.5719 - val_accuracy: 0.8950\n",
      "Epoch 223/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9934 - val_loss: 0.5316 - val_accuracy: 0.9081\n",
      "Epoch 224/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0671 - accuracy: 0.9980 - val_loss: 0.5374 - val_accuracy: 0.9081\n",
      "Epoch 225/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0975 - accuracy: 0.9914 - val_loss: 0.4647 - val_accuracy: 0.9239\n",
      "Epoch 226/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9836 - val_loss: 0.4551 - val_accuracy: 0.9108\n",
      "Epoch 227/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 0.9961 - val_loss: 0.5442 - val_accuracy: 0.9029\n",
      "Epoch 228/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0706 - accuracy: 0.9974 - val_loss: 0.7073 - val_accuracy: 0.8793\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0770 - accuracy: 0.9934 - val_loss: 0.5023 - val_accuracy: 0.9186\n",
      "Epoch 230/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9895 - val_loss: 0.5518 - val_accuracy: 0.9003\n",
      "Epoch 231/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1144 - accuracy: 0.9829 - val_loss: 0.5785 - val_accuracy: 0.8950\n",
      "Epoch 232/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0982 - accuracy: 0.9849 - val_loss: 0.5712 - val_accuracy: 0.8976\n",
      "Epoch 233/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0907 - accuracy: 0.9901 - val_loss: 0.4753 - val_accuracy: 0.9134\n",
      "Epoch 234/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0751 - accuracy: 0.9961 - val_loss: 0.5013 - val_accuracy: 0.9186\n",
      "Epoch 235/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9941 - val_loss: 0.5936 - val_accuracy: 0.9029\n",
      "Epoch 236/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9961 - val_loss: 0.5468 - val_accuracy: 0.9134\n",
      "Epoch 237/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0659 - accuracy: 0.9980 - val_loss: 0.5616 - val_accuracy: 0.9186\n",
      "Epoch 238/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9987 - val_loss: 0.5784 - val_accuracy: 0.9108\n",
      "Epoch 239/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1151 - accuracy: 0.9842 - val_loss: 0.5175 - val_accuracy: 0.8793\n",
      "Epoch 240/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0842 - accuracy: 0.9908 - val_loss: 0.4842 - val_accuracy: 0.9186\n",
      "Epoch 241/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0771 - accuracy: 0.9947 - val_loss: 0.5416 - val_accuracy: 0.9081\n",
      "Epoch 242/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1199 - accuracy: 0.9789 - val_loss: 0.5695 - val_accuracy: 0.9055\n",
      "Epoch 243/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1006 - accuracy: 0.9849 - val_loss: 0.4653 - val_accuracy: 0.9081\n",
      "Epoch 244/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9967 - val_loss: 0.5204 - val_accuracy: 0.9239\n",
      "Epoch 245/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9980 - val_loss: 0.5559 - val_accuracy: 0.9186\n",
      "Epoch 246/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0709 - accuracy: 0.9974 - val_loss: 0.5333 - val_accuracy: 0.9186\n",
      "Epoch 247/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0684 - accuracy: 0.9974 - val_loss: 0.5710 - val_accuracy: 0.9108\n",
      "Epoch 248/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0669 - accuracy: 0.9980 - val_loss: 0.5957 - val_accuracy: 0.9108\n",
      "Epoch 249/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0662 - accuracy: 0.9974 - val_loss: 0.5771 - val_accuracy: 0.9160\n",
      "Epoch 250/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0853 - accuracy: 0.9914 - val_loss: 0.4940 - val_accuracy: 0.9186\n",
      "Epoch 251/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9934 - val_loss: 0.5688 - val_accuracy: 0.9108\n",
      "Epoch 252/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0753 - accuracy: 0.9954 - val_loss: 0.5424 - val_accuracy: 0.9108\n",
      "Epoch 253/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9928 - val_loss: 0.5306 - val_accuracy: 0.9134\n",
      "Epoch 254/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9914 - val_loss: 0.5385 - val_accuracy: 0.9160\n",
      "Epoch 255/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9954 - val_loss: 0.5245 - val_accuracy: 0.9213\n",
      "Epoch 256/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0705 - accuracy: 0.9954 - val_loss: 0.5418 - val_accuracy: 0.9160\n",
      "Epoch 257/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0689 - accuracy: 0.9954 - val_loss: 0.6613 - val_accuracy: 0.8976\n",
      "Epoch 258/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0711 - accuracy: 0.9954 - val_loss: 0.6966 - val_accuracy: 0.8740\n",
      "Epoch 259/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0778 - accuracy: 0.9934 - val_loss: 0.6929 - val_accuracy: 0.8845\n",
      "Epoch 260/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9908 - val_loss: 0.9999 - val_accuracy: 0.8451\n",
      "Epoch 261/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.1138 - accuracy: 0.9783 - val_loss: 0.6005 - val_accuracy: 0.8924\n",
      "Epoch 262/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0973 - accuracy: 0.9868 - val_loss: 0.6828 - val_accuracy: 0.8819\n",
      "Epoch 263/500\n",
      "48/48 [==============================] - 0s 9ms/step - loss: 0.0788 - accuracy: 0.9947 - val_loss: 0.5543 - val_accuracy: 0.9081\n",
      "Epoch 264/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9921 - val_loss: 0.5544 - val_accuracy: 0.9003\n",
      "Epoch 265/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.9849 - val_loss: 0.5110 - val_accuracy: 0.8950\n",
      "Epoch 266/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.9184 - val_loss: 0.3744 - val_accuracy: 0.8898\n",
      "Epoch 267/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9842 - val_loss: 0.4558 - val_accuracy: 0.9160\n",
      "Epoch 268/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9967 - val_loss: 0.4914 - val_accuracy: 0.9213\n",
      "Epoch 269/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0710 - accuracy: 0.9967 - val_loss: 0.5093 - val_accuracy: 0.9239\n",
      "Epoch 270/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0899 - accuracy: 0.9908 - val_loss: 0.5181 - val_accuracy: 0.9160\n",
      "Epoch 271/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9947 - val_loss: 0.5889 - val_accuracy: 0.9003\n",
      "Epoch 272/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9967 - val_loss: 0.5326 - val_accuracy: 0.9134\n",
      "Epoch 273/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0874 - accuracy: 0.9901 - val_loss: 0.5971 - val_accuracy: 0.8976\n",
      "Epoch 274/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0852 - accuracy: 0.9921 - val_loss: 0.6132 - val_accuracy: 0.9003\n",
      "Epoch 275/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9961 - val_loss: 0.5339 - val_accuracy: 0.9134\n",
      "Epoch 276/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9941 - val_loss: 0.5372 - val_accuracy: 0.9081\n",
      "Epoch 277/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0784 - accuracy: 0.9921 - val_loss: 0.5352 - val_accuracy: 0.9186\n",
      "Epoch 278/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0884 - accuracy: 0.9895 - val_loss: 0.7803 - val_accuracy: 0.8530\n",
      "Epoch 279/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0922 - accuracy: 0.9875 - val_loss: 0.5210 - val_accuracy: 0.9108\n",
      "Epoch 280/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 0.9954 - val_loss: 0.5517 - val_accuracy: 0.9108\n",
      "Epoch 281/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9980 - val_loss: 0.5589 - val_accuracy: 0.9160\n",
      "Epoch 282/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0728 - accuracy: 0.9954 - val_loss: 0.5417 - val_accuracy: 0.9213\n",
      "Epoch 283/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0765 - accuracy: 0.9954 - val_loss: 0.5237 - val_accuracy: 0.9108\n",
      "Epoch 284/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0664 - accuracy: 0.9974 - val_loss: 0.5358 - val_accuracy: 0.9213\n",
      "Epoch 285/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0639 - accuracy: 0.9980 - val_loss: 0.5476 - val_accuracy: 0.9108\n",
      "Epoch 286/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9901 - val_loss: 0.5920 - val_accuracy: 0.9003\n",
      "Epoch 287/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0926 - accuracy: 0.9882 - val_loss: 0.6384 - val_accuracy: 0.8950\n",
      "Epoch 288/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0702 - accuracy: 0.9967 - val_loss: 0.6010 - val_accuracy: 0.9055\n",
      "Epoch 289/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9934 - val_loss: 0.5415 - val_accuracy: 0.9055\n",
      "Epoch 290/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9954 - val_loss: 0.5966 - val_accuracy: 0.9160\n",
      "Epoch 291/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0906 - accuracy: 0.9882 - val_loss: 0.5415 - val_accuracy: 0.9055\n",
      "Epoch 292/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9941 - val_loss: 0.6383 - val_accuracy: 0.9003\n",
      "Epoch 293/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9974 - val_loss: 0.6484 - val_accuracy: 0.9029\n",
      "Epoch 294/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9954 - val_loss: 0.5532 - val_accuracy: 0.9160\n",
      "Epoch 295/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0714 - accuracy: 0.9967 - val_loss: 0.6095 - val_accuracy: 0.9081\n",
      "Epoch 296/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0748 - accuracy: 0.9947 - val_loss: 0.5438 - val_accuracy: 0.9213\n",
      "Epoch 297/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0843 - accuracy: 0.9921 - val_loss: 0.5391 - val_accuracy: 0.9186\n",
      "Epoch 298/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0767 - accuracy: 0.9961 - val_loss: 0.5436 - val_accuracy: 0.9160\n",
      "Epoch 299/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0649 - accuracy: 0.9987 - val_loss: 0.5706 - val_accuracy: 0.9134\n",
      "Epoch 300/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0623 - accuracy: 0.9987 - val_loss: 0.7259 - val_accuracy: 0.8924\n",
      "Epoch 301/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.9947 - val_loss: 0.6569 - val_accuracy: 0.8898\n",
      "Epoch 302/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0773 - accuracy: 0.9947 - val_loss: 0.6193 - val_accuracy: 0.9055\n",
      "Epoch 303/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0877 - accuracy: 0.9888 - val_loss: 0.5467 - val_accuracy: 0.8950\n",
      "Epoch 304/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1105 - accuracy: 0.9829 - val_loss: 0.6156 - val_accuracy: 0.8793\n",
      "Epoch 305/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9954 - val_loss: 0.5171 - val_accuracy: 0.9213\n",
      "Epoch 306/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0725 - accuracy: 0.9954 - val_loss: 0.5455 - val_accuracy: 0.9055\n",
      "Epoch 307/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9934 - val_loss: 0.5228 - val_accuracy: 0.9108\n",
      "Epoch 308/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0742 - accuracy: 0.9941 - val_loss: 0.5808 - val_accuracy: 0.9055\n",
      "Epoch 309/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0650 - accuracy: 0.9974 - val_loss: 0.5615 - val_accuracy: 0.9160\n",
      "Epoch 310/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0629 - accuracy: 0.9987 - val_loss: 0.5568 - val_accuracy: 0.9186\n",
      "Epoch 311/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0608 - accuracy: 0.9980 - val_loss: 0.5534 - val_accuracy: 0.9160\n",
      "Epoch 312/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0758 - accuracy: 0.9934 - val_loss: 0.7492 - val_accuracy: 0.8609\n",
      "Epoch 313/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9664 - val_loss: 0.4863 - val_accuracy: 0.8950\n",
      "Epoch 314/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9875 - val_loss: 0.5232 - val_accuracy: 0.9055\n",
      "Epoch 315/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9954 - val_loss: 0.5577 - val_accuracy: 0.9081\n",
      "Epoch 316/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9934 - val_loss: 0.5902 - val_accuracy: 0.8976\n",
      "Epoch 317/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0685 - accuracy: 0.9961 - val_loss: 0.5576 - val_accuracy: 0.9081\n",
      "Epoch 318/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9941 - val_loss: 0.5780 - val_accuracy: 0.9055\n",
      "Epoch 319/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9908 - val_loss: 0.5948 - val_accuracy: 0.9029\n",
      "Epoch 320/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0848 - accuracy: 0.9921 - val_loss: 0.5178 - val_accuracy: 0.9108\n",
      "Epoch 321/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0909 - accuracy: 0.9908 - val_loss: 0.5015 - val_accuracy: 0.9160\n",
      "Epoch 322/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0907 - accuracy: 0.9849 - val_loss: 0.6555 - val_accuracy: 0.8871\n",
      "Epoch 323/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1241 - accuracy: 0.9743 - val_loss: 0.4878 - val_accuracy: 0.9055\n",
      "Epoch 324/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9941 - val_loss: 0.5108 - val_accuracy: 0.9029\n",
      "Epoch 325/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0668 - accuracy: 0.9980 - val_loss: 0.5192 - val_accuracy: 0.9134\n",
      "Epoch 326/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9980 - val_loss: 0.5563 - val_accuracy: 0.9108\n",
      "Epoch 327/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9961 - val_loss: 0.6106 - val_accuracy: 0.8976\n",
      "Epoch 328/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0884 - accuracy: 0.9882 - val_loss: 0.5226 - val_accuracy: 0.9186\n",
      "Epoch 329/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9901 - val_loss: 0.5110 - val_accuracy: 0.9003\n",
      "Epoch 330/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9934 - val_loss: 0.5307 - val_accuracy: 0.9055\n",
      "Epoch 331/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0638 - accuracy: 0.9980 - val_loss: 0.5162 - val_accuracy: 0.9134\n",
      "Epoch 332/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1012 - accuracy: 0.9842 - val_loss: 0.5037 - val_accuracy: 0.8819\n",
      "Epoch 333/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9914 - val_loss: 0.4952 - val_accuracy: 0.9213\n",
      "Epoch 334/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0760 - accuracy: 0.9954 - val_loss: 0.4688 - val_accuracy: 0.9134\n",
      "Epoch 335/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0949 - accuracy: 0.9875 - val_loss: 0.6522 - val_accuracy: 0.8714\n",
      "Epoch 336/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1379 - accuracy: 0.9743 - val_loss: 0.5173 - val_accuracy: 0.8871\n",
      "Epoch 337/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9921 - val_loss: 0.4858 - val_accuracy: 0.9108\n",
      "Epoch 338/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9967 - val_loss: 0.5615 - val_accuracy: 0.8924\n",
      "Epoch 339/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9961 - val_loss: 0.4867 - val_accuracy: 0.9186\n",
      "Epoch 340/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0678 - accuracy: 0.9967 - val_loss: 0.5256 - val_accuracy: 0.9186\n",
      "Epoch 341/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0742 - accuracy: 0.9947 - val_loss: 0.5539 - val_accuracy: 0.9160\n",
      "Epoch 342/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9947 - val_loss: 0.5723 - val_accuracy: 0.8950\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9961 - val_loss: 0.5397 - val_accuracy: 0.9055\n",
      "Epoch 344/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0720 - accuracy: 0.9954 - val_loss: 0.5266 - val_accuracy: 0.9029\n",
      "Epoch 345/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9947 - val_loss: 0.6564 - val_accuracy: 0.8845\n",
      "Epoch 346/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9849 - val_loss: 0.5005 - val_accuracy: 0.9134\n",
      "Epoch 347/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9954 - val_loss: 0.4980 - val_accuracy: 0.9239\n",
      "Epoch 348/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9947 - val_loss: 0.5660 - val_accuracy: 0.9108\n",
      "Epoch 349/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0708 - accuracy: 0.9941 - val_loss: 0.5280 - val_accuracy: 0.9186\n",
      "Epoch 350/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9941 - val_loss: 0.6332 - val_accuracy: 0.8845\n",
      "Epoch 351/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0677 - accuracy: 0.9974 - val_loss: 0.6887 - val_accuracy: 0.8819\n",
      "Epoch 352/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0750 - accuracy: 0.9941 - val_loss: 0.5481 - val_accuracy: 0.9134\n",
      "Epoch 353/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0685 - accuracy: 0.9954 - val_loss: 0.5673 - val_accuracy: 0.9081\n",
      "Epoch 354/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9895 - val_loss: 0.4549 - val_accuracy: 0.9213\n",
      "Epoch 355/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9967 - val_loss: 0.5412 - val_accuracy: 0.9108\n",
      "Epoch 356/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9967 - val_loss: 0.6276 - val_accuracy: 0.9029\n",
      "Epoch 357/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0662 - accuracy: 0.9967 - val_loss: 0.5797 - val_accuracy: 0.9055\n",
      "Epoch 358/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9967 - val_loss: 0.6044 - val_accuracy: 0.8976\n",
      "Epoch 359/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9961 - val_loss: 0.6770 - val_accuracy: 0.8976\n",
      "Epoch 360/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9934 - val_loss: 0.5728 - val_accuracy: 0.9081\n",
      "Epoch 361/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9947 - val_loss: 0.5180 - val_accuracy: 0.9134\n",
      "Epoch 362/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9967 - val_loss: 0.6042 - val_accuracy: 0.8898\n",
      "Epoch 363/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9829 - val_loss: 0.5935 - val_accuracy: 0.9055\n",
      "Epoch 364/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9822 - val_loss: 0.5262 - val_accuracy: 0.9055\n",
      "Epoch 365/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 0.9882 - val_loss: 0.4849 - val_accuracy: 0.9186\n",
      "Epoch 366/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0751 - accuracy: 0.9901 - val_loss: 0.5150 - val_accuracy: 0.9134\n",
      "Epoch 367/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9908 - val_loss: 0.5097 - val_accuracy: 0.8950\n",
      "Epoch 368/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0772 - accuracy: 0.9941 - val_loss: 0.5318 - val_accuracy: 0.9029\n",
      "Epoch 369/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9961 - val_loss: 0.5333 - val_accuracy: 0.9239\n",
      "Epoch 370/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0694 - accuracy: 0.9947 - val_loss: 0.5550 - val_accuracy: 0.9108\n",
      "Epoch 371/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0690 - accuracy: 0.9967 - val_loss: 0.5368 - val_accuracy: 0.9186\n",
      "Epoch 372/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0712 - accuracy: 0.9954 - val_loss: 0.6419 - val_accuracy: 0.8871\n",
      "Epoch 373/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0661 - accuracy: 0.9961 - val_loss: 0.5490 - val_accuracy: 0.9108\n",
      "Epoch 374/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9987 - val_loss: 0.5486 - val_accuracy: 0.9213\n",
      "Epoch 375/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9941 - val_loss: 0.5956 - val_accuracy: 0.9029\n",
      "Epoch 376/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0644 - accuracy: 0.9967 - val_loss: 0.6712 - val_accuracy: 0.8819\n",
      "Epoch 377/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9816 - val_loss: 0.4982 - val_accuracy: 0.9134\n",
      "Epoch 378/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0903 - accuracy: 0.9895 - val_loss: 0.5486 - val_accuracy: 0.8871\n",
      "Epoch 379/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0719 - accuracy: 0.9954 - val_loss: 0.5389 - val_accuracy: 0.9055\n",
      "Epoch 380/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0688 - accuracy: 0.9961 - val_loss: 0.5767 - val_accuracy: 0.9003\n",
      "Epoch 381/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.1253 - accuracy: 0.9750 - val_loss: 0.4564 - val_accuracy: 0.9134\n",
      "Epoch 382/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9934 - val_loss: 0.4939 - val_accuracy: 0.9134\n",
      "Epoch 383/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9928 - val_loss: 0.5994 - val_accuracy: 0.8898\n",
      "Epoch 384/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0906 - accuracy: 0.9875 - val_loss: 0.5116 - val_accuracy: 0.9186\n",
      "Epoch 385/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9941 - val_loss: 0.5458 - val_accuracy: 0.9108\n",
      "Epoch 386/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9947 - val_loss: 0.5228 - val_accuracy: 0.9134\n",
      "Epoch 387/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9888 - val_loss: 0.4930 - val_accuracy: 0.9029\n",
      "Epoch 388/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0612 - accuracy: 0.9980 - val_loss: 0.5711 - val_accuracy: 0.9003\n",
      "Epoch 389/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0681 - accuracy: 0.9947 - val_loss: 0.5459 - val_accuracy: 0.9160\n",
      "Epoch 390/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0800 - accuracy: 0.9928 - val_loss: 0.5839 - val_accuracy: 0.9055\n",
      "Epoch 391/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0619 - accuracy: 0.9980 - val_loss: 0.5016 - val_accuracy: 0.9239\n",
      "Epoch 392/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0695 - accuracy: 0.9934 - val_loss: 0.5903 - val_accuracy: 0.9081\n",
      "Epoch 393/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9954 - val_loss: 0.5288 - val_accuracy: 0.9213\n",
      "Epoch 394/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0824 - accuracy: 0.9901 - val_loss: 0.5901 - val_accuracy: 0.9029\n",
      "Epoch 395/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0943 - accuracy: 0.9875 - val_loss: 0.5299 - val_accuracy: 0.9108\n",
      "Epoch 396/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0659 - accuracy: 0.9954 - val_loss: 0.5262 - val_accuracy: 0.9160\n",
      "Epoch 397/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0668 - accuracy: 0.9954 - val_loss: 0.5417 - val_accuracy: 0.9108\n",
      "Epoch 398/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0904 - accuracy: 0.9895 - val_loss: 0.5604 - val_accuracy: 0.9055\n",
      "Epoch 399/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9770 - val_loss: 0.4809 - val_accuracy: 0.9160\n",
      "Epoch 400/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0676 - accuracy: 0.9967 - val_loss: 0.4855 - val_accuracy: 0.9160\n",
      "Epoch 401/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0718 - accuracy: 0.9954 - val_loss: 0.4775 - val_accuracy: 0.9213\n",
      "Epoch 402/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0642 - accuracy: 0.9967 - val_loss: 0.5080 - val_accuracy: 0.9291\n",
      "Epoch 403/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0680 - accuracy: 0.9947 - val_loss: 0.5371 - val_accuracy: 0.9055\n",
      "Epoch 404/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0656 - accuracy: 0.9967 - val_loss: 0.5545 - val_accuracy: 0.9160\n",
      "Epoch 405/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0653 - accuracy: 0.9961 - val_loss: 0.5834 - val_accuracy: 0.9108\n",
      "Epoch 406/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0586 - accuracy: 0.9993 - val_loss: 0.5765 - val_accuracy: 0.9108\n",
      "Epoch 407/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0598 - accuracy: 0.9993 - val_loss: 0.5761 - val_accuracy: 0.9108\n",
      "Epoch 408/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9901 - val_loss: 0.5441 - val_accuracy: 0.9108\n",
      "Epoch 409/500\n",
      "48/48 [==============================] - 0s 7ms/step - loss: 0.0894 - accuracy: 0.9914 - val_loss: 0.5494 - val_accuracy: 0.8950\n",
      "Epoch 410/500\n",
      "48/48 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9967 - val_loss: 0.5484 - val_accuracy: 0.9160\n",
      "Epoch 411/500\n",
      "48/48 [==============================] - 0s 5ms/step - loss: 0.0783 - accuracy: 0.9928 - val_loss: 0.5089 - val_accuracy: 0.9160\n",
      "Epoch 412/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9921 - val_loss: 0.4747 - val_accuracy: 0.9160\n",
      "Epoch 413/500\n",
      "48/48 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9993 - val_loss: 0.5015 - val_accuracy: 0.9213\n",
      "Epoch 414/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9987 - val_loss: 0.5106 - val_accuracy: 0.9160\n",
      "Epoch 415/500\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9941 - val_loss: 0.6275 - val_accuracy: 0.8819\n",
      "Epoch 416/500\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9928 - val_loss: 0.5838 - val_accuracy: 0.9003\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=500, validation_split=0.2, callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9832347569843898"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008366141754848"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(history.history[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVf643zM1PaST0Jv03sRCEXVFxbUidl3L2ld/rqvr7rr6Xduuvay9rYpYsCAKFgQURJDeew8hhATS22Tm/P449869U5JMICGB3Pd58mRmbju3ffo5R0gpsbCwsLBovdiauwEWFhYWFs2LpQgsLCwsWjmWIrCwsLBo5ViKwMLCwqKVYykCCwsLi1aOpQgsLCwsWjmWIrBoVQgh3hVCPBLhujuFEKc3dZssLJobSxFYWFhYtHIsRWBhcQwihHA0dxssjh8sRWDR4tBCMvcKIVYLIcqEEG8JITKEELOEECVCiNlCiCTT+ucJIdYJIQqFEPOEEL1NywYLIZZr230MRAUd61whxEpt24VCiAERtvEcIcQKIUSxEGKPEOKhoOWnaPsr1JZfq/0eLYR4WgixSwhRJIRYoP02VgiRHeY6nK59fkgIMU0I8YEQohi4VggxQgjxq3aMfUKIl4QQLtP2fYUQPwghDgoh9gshHhBCtBVClAshUkzrDRVCHBBCOCM5d4vjD0sRWLRULgLOAE4AJgKzgAeAVNRzeyeAEOIEYCpwF5AGzARmCCFcmlD8EngfSAY+1faLtu0Q4G3gj0AK8BrwlRDCHUH7yoCrgTbAOcAtQojztf121Nr7otamQcBKbbungKHASVqb/gL4IrwmvwemacecAniBu7VrMgoYD9yqtSEemA18C2QB3YEfpZS5wDxgkmm/VwIfSSk9EbbD4jjDUgQWLZUXpZT7pZR7gfnAYinlCillFfAFMFhb71LgGynlD5ogewqIRgnaEwEn8JyU0iOlnAYsMR3jRuA1KeViKaVXSvk/oErbrk6klPOklGuklD4p5WqUMhqjLb4CmC2lnKodt0BKuVIIYQP+APxJSrlXO+ZC7Zwi4Vcp5ZfaMSuklMuklIuklDVSyp0oRaa34VwgV0r5tJSyUkpZIqVcrC37H0r4I4SwA5ehlKVFK8VSBBYtlf2mzxVhvsdpn7OAXfoCKaUP2AO005btlYEjK+4yfe4E3KOFVgqFEIVAB227OhFCjBRCzNVCKkXAzSjLHG0f28JslooKTYVbFgl7gtpwghDiayFErhYueiyCNgBMB/oIIbqivK4iKeVvh9kmi+MASxFYHOvkoAQ6AEIIgRKCe4F9QDvtN52Ops97gEellG1MfzFSyqkRHPdD4Cugg5QyEXgV0I+zB+gWZpt8oLKWZWVAjOk87KiwkpngoYJfATYCPaSUCajQWX1tQEpZCXyC8lyuwvIGWj2WIrA41vkEOEcIMV5Ldt6DCu8sBH4FaoA7hRAOIcSFwAjTtm8AN2vWvRBCxGpJ4PgIjhsPHJRSVgohRgCXm5ZNAU4XQkzSjpsihBikeStvA88IIbKEEHYhxCgtJ7EZiNKO7wT+DtSXq4gHioFSIUQv4BbTsq+BtkKIu4QQbiFEvBBipGn5e8C1wHnABxGcr8VxjKUILI5ppJSbUPHuF1EW90RgopSyWkpZDVyIEniHUPmEz03bLkXlCV7Slm/V1o2EW4H/E0KUAA+iFJK+393A2SildBCVKB6oLf4zsAaVqzgI/BuwSSmLtH2+ifJmyoCAKqIw/BmlgEpQSu1jUxtKUGGfiUAusAUYZ1r+CypJvVzLL1i0YoQ1MY2FRetECDEH+FBK+WZzt8WiebEUgYVFK0QIMRz4AZXjKGnu9lg0L1ZoyMKilSGE+B+qj8FdlhKwAMsjsLCwsGj1WB6BhYWFRSvnmBu4KjU1VXbu3Lm5m2FhYWFxTLFs2bJ8KWVw3xTgGFQEnTt3ZunSpc3dDAsLC4tjCiHErtqWWaEhCwsLi1aOpQgsLCwsWjmWIrCwsLBo5RxzOYJweDwesrOzqaysbO6mHDdERUXRvn17nE5rrhILi+Od40IRZGdnEx8fT+fOnQkcaNLicJBSUlBQQHZ2Nl26dGnu5lhYWDQxTRYaEkK8LYTIE0KsrWW5EEK8IITYKtSUhEMO91iVlZWkpKRYSqCREEKQkpJieVgWFq2EpswRvAucVcfyCUAP7e8m1Njqh42lBBoX63paWLQemkwRSCl/Rg2zWxu/B96TikVAGyFEZlO1x6L1UV5dQ2F5dXM344ioqPaSXxrpTJYtg7KqGtZkF1HjDT8Vc6XHy6GyY/O+FFV4KKlsmqmdS6tqeGnOFmau2ef/zeeTfLh4Nxv2FTfJMXWas2qoHYFT72Vrv4UghLhJCLFUCLH0wIEDR6VxDaGwsJCXX365wdudffbZFBYW1rnOgw8+yOzZsw+3ac3Cwm35nPvifPKKQ0NL2YfKw/6us7+4kvlbDjD2ybnkFtUfmiqu9PDij1s4GEawXP/uUgb93w94fWo8rbKqGp75fhMV1d6QdV+Zt427P14Z8jtAQWkVT363kfLqmnrbA1BYXs2ugjIA8kur2JlfFrLOQ1+t45kfNuPzSd7/dSeLthcELJdSsmzXIXo/+C3jn/4Jn88YE+z9X3dyzgvzue3D5Yx/eh6Pz9pAQ8cMK6n08N26XHIKKygsr2bz/hL/cXUqqr1c9dZiPl26h0+W7uGs537mp80H2FVQ5ldOlR4v/527leW7D7HnYDmVHi8TX1rAxJcW8PK80Jkyt+aVMObJuQx7dDbTV+4NOedgnpi1keGPzubdX3YAsHZvEWc/P5+CIOW4fPchVu4p9F/3cCzcms8nS5TI2VdUwbdr9/Ht2n0s3l6AzycpKvf4r0NwuzbmFpNXUsnIx2Zz6WuLWLH7UK3HAfh27T4mv/4ra7JVe/cVVYSsk1tUyfYDpSzbdYhdBWXc88lKnvp+M7d9uJxKj5dVewr5bedBHvhiDRNq2Udj0ZzJ4nCxh7BPs5TydeB1gGHDhrW4UfJ0RXDrrbcG/O71erHb7bVuN3PmzHr3/X//93+H3S6vz0dZlZf4KEdEoR6flCDBZgu/rs8nmfjSAsb3SmfiwCzKq70M7NAmZL0nZm1k7d5iHp25gecnD/b/LqXklH/PJd7tYM3Dv2P57kMkx7jonBrrX+fUf8+lWrMk52zM4+Kh7XE5bJRV1fDg9HV0TI6huNLDx0v2cFK3FGxC8O26XOZuymPazScFtP1XTbjO2ZjHGX0y+O/crbw8bxsZiVFcMbITxZUeEqKceLw+/v3tRgBuPLUrfbISAs7nxTlbeXfhTv47dxvjeqbxt3P60D09zr98wZZ82sQ46dcukV0FZYx5ch52m2DLIxO44OVf2HOwgrUP/444t3rdth8o5d2FOwFwO2w8+d0mEqIcrHzwTGw2wfSVe/nTR4ZSKqrwkFNUwdq9RfRv34Z/TF9HvNtBYbmHaq+P137azrBOyczZuJ87TuvBsz9sJldTthcMbseFQ9ojpeTbtbmM65VOlNPO6z9v58U5W+nXLoGN+0qo8UnevHoYD05fy2tXDaN/+0Re+Wkb87fkM39Lvr8tM1fv4+OlSpheMrQ9nVNjefK7TQDERzk4p38m2w8oYfzMD5sZ2KENHZKieeSbDfTLSmDFnkLKq7y47DZe/3k7Ewdk8eBXa9m8v5TC8mo+vPFEUuPUxGwHy6p5e8EOqr0+Hv56PSO7pvD/PlnJ5v2l/Lq9gF+2FnDDqV0oKK1m0mu/qja4HQzplMS6nGIm9GvLKT1SmbMhjzP7ZnD9/9SIBNOWZ3OorJoteaX+8xrVNcX/vOx84hz/76//vI3HZm4MeB7W7yvmgpcXMv22k3n6h81syi3m+7vHkBjtpNLjZc7GPB74Yg2F5R4mvrQAgJOfmMOrVw7FJ2HK4l1ce1Jn3l24M+Da6kgJ905bzYxVOZzWK93/+9er9nHj6K4h6zcGzakIslFzy+q0R80/e8xx//33s23bNgYNGoTT6SQuLo7MzExWrlzJ+vXrOf/889mzZw+VlZX86U9/4qabbgKM4TJKS0uZMGECp5xyCgsXLqRdu3ZMnz6d6Ohorr32Ws4991wuvvhiOnfuzDXXXMOMGTPweDx8+umn9OrViwMHDjDp0snk5RfQf9AQ5s+dzYply/C548grqSItzk1mm2hAWXA5hRW0S4rG7TCUVHWNl025pcRHOQIEs5nfdh5kXU4x63KKeWHOVgBevXIIZ/XLRErJjvwy4twOVmcXATB9ZQ5pcW6uHtWZWLed3QfLASipquHN+dt55JsNAGx/7Gz+9uVahndO8isBgAe+WMMLP25h0QPjeW72Zj5bHjhh17xNB/zrL99dyJTFu7hqVGeAAIvx9Z+3cXrvdNblKPe6qMLDV6tyuHPqCr687WQOlhnrTl+5N0ARHCqr9luuUU4bczcdoHdmNpeN6MjeQmWhXfnWYgCeuLA/P29RHqvXJ/lhw372HFTr3DplOS9eNpjv1uXyl2mr/fv/XDun4soaFmzNZ/QJabz/qzESwP0TevHErI1c/+5SNu0v4Z4zTgDgjWuGcWLXFHKLKjnx8R+5dcoyPF7J1N+UkO6dmUBFdQ1//nQVbROjcDts3DJlOaf3zuDNa4b5hfXavUbI4dYPl1Nd4+Om95cy/baT+XbtPrqlxdIpJZakGBfZh8qZv8XwyD9dZtyPgR3asGpPIR9pCvqWsd246q3fuPG9pdwxrjtzNuYxZ2MeAPed1QuXw8a/vl7P7A37+WDRbuN8P1vNA2f3pmtaHLPW7qPa6+O9P4zg6rd/Y96mA2zer4T3m/N3sHJPIeXVNcS41HN8/SldmLYsmwVb8zmpWwrvL9rF+4vUtdSVF8BvO1TE+sLB7bhxdFdmrdnnf57VvVAGwqo9hQFKYGzPNAa0S/Sv+9nybH7erK7H9e8uoVNKLEUV1czekEcwPgk3vb+MEV2S+W3HQapqfOw9pJ6NeLcDm01wxciOjOyawjVv/8aMVUoUztmYR9fUWOKjHLz283aGd0lmUBjj60hpTkXwFXC7EOIjYCRQJKXcV8829fLwjHWsz2nceFqfrAT+ObFvrcufeOIJ1q5dy8qVK5k3bx7nnHMOa9eu9Zdevv322yQnJ1NRUcHw4cO56KKLSElJCdjHli1bmDp1Km+88QaTJk3is88+48orrww5VmpqKsuXL+fll1/mqaee4s033+Thhx9m+MmjufKPf2LhvB/5+P13KK+uwSdUCKSksobEqhpKqmpw2ASlVTVsP1BGzww1Na/NJjhY5kEiKalU4Y+9h8opKK1i1pp9jD4hDSHghR+3hLTnrQU7OKtfJk9/v5mX5m7l/gm9APjPxQP4y7TVvLlgB28u2EH39DhO7Jrs305XAgCz1uYy9bfdTP1td8j+c4sr2ZFfxter93FW37b855IBrM0uontGHKWVNazOLmLMCWnc+dEK/jF9Ha/+tJ2rR3ViwVZlaZ3Vty3frsvlrQU7WL5LufNb9pf6he2Vby6mtKqG1DgXLruN/ZolXVzp4e6PVvLjxjxcDhszbj+FPlkJXPzqQuZtOsCUxbspqjBixe2Torn/8zUAnNYrnTkb87jvs9W47DYuHd6B9xft4tkfNvPxkj3Eux2c0SeDz1fsZduBMsackMbavUW8v2gXwzsns2ZvEWf0yeCvE3pRroWxNmkhiyXaOXRKUfPct02M4oSMOLYdKOP8QVl8uTIHu00w4/aTqfb6OOeFBTzw+RquGNkJgNkb9nOorJo9h8qJctqo9BiKt7rGx6Rh7Zmxah+3TlnOlrxS7jytB3dryuep7zaxWBOiXVJj2aGFvJ66ZCAXD23P+4t28Y8v13L1qE6c2iONl68Ywq1TlvPFir3Eux3cPLYbboeNa07q7FfK0zWBd3rvdLqkxvLG/B3M3pDHXaf3wOP1YbcJTumeSkaC2++1Aazco0Kqh8o9LNpewLkDMvnHuX2476xe1Ph8xLgcjH1yLjsLyjm5ewpXj+qMy24js00UZz03H4AxPdPonZnACRnxSKCw3MP7i3aRU1hBsdvD379cS5sYJwvuO41opx275m32yUrk5g+W8YlJuSzddYiluwLDRecNzGJHfhnjeqXz2bJs9hZW+JXQ8l2HiHU7uHBIO56ZNAivT2K3CapqQsOWJ3VP4aoTO3P9/5Ywd2PesaUIhBBTgbFAqhAiG/gn4ASQUr4KzETN67oVKAeua6q2HG1GjBhBly5dqKiuQQIvvPACX3zxBQB79uxhy5YttElKRg/7llfV0L5jZ9p1601xhYfOPfuxbpNhoVTX+NijWdMXXnghAEOHDuXzz9X0uwsWLODZNz4gzu3gxssv5L7b21BaXYOwqYfK4/Ox7UApEojVwhMer4+1OUXYhKBn23iqtQfQYRd4fZKCsmoqPD5u+Ww56fFu+rVLZOG2Ah67oD/DOyexbNch8kureOr7zazLKeKluZqH8JOKC5/aI5WXLh/Mp0uz+WnzAbbmlbI1r5TTe2cwe8P+gOs1ZXHgWFjXn9KFtxbs8H//fl0ueSVVdEuPJSHKyUndUwFIj4euaSpE8/zkwYx6/Ef2Flbw+CwlMPq3S+TfFw1gY24xj3yzgczEKNxOO1+sUBb+ab3SWbWnkNIquGRYB37Zms+O/DK+XbuP7EMV/KiFpi4c0o7+7RMBGNklxX+OT1zYn9d/3k7bxCjeumY4n6/Ixmmzcd6gLAY+/D2F5R5+PyiLf53fj7KqGn846JlJA7lgcDvmbMqjsNxD17RY+mQl8NpP25ixKoeqGh9XndiJrmlxIbmP33YU4HbYyIiP8v/2r9/3o6SyhtP7ZDChfyZJMS4cdhsOu43bx3Xnnk9X8aUpHq/H888bmMXBsmquO7kLj3yzgeoaL4+c35/emQk8PGM9AAM7JPq3G94lGeaqz5/ePIphj8z232uAq07sxKiuKf6w2bie6bgcNrbnl9E3K4HbxnX37ys+Sj2Hv2zNJ8Zl57WrhlFaVcOWvFJ+3VbAK/O2cY52LjaboH1SDPuLqxjRJZnN+0soLFdKeNWeQoorPf7nwOWw4dJSn93S4thZUE7vtgn8rm9b/7HH9Uxj7qYDDOmYBIDdJrjnzJ6s2H2I9xftYt3eYp75YTMHSqv41+/7+kN6Omf2ycBpF1R6fKTFuzlQEpivyEqMIqeokr5ZCbxwmQqNXjaiA6MenwOokNqny7IpqvCQEuvytwHA7bAzonMyWw+UMutPp1Ll8ZES5yLW7eCbO071X7fGpskUgZTysnqWS+C2xj5uXZb70SI2VoVWtuSVsuTXBfwweza//vorMTExjB4zhvzCEnIKK/D6fFRU11BaVYPD6eRASRU2G3iloKS8kpJKDz6fZH9xJYfKq5ES3G4VPxXCRkVVNT4pkVLi8flwOWzYbQIhBIfKPCS6JE67DY8p3FJWFZjw9ElJYbmHqhq1jtcn/eskx7r44PqR3PfZauZszGNU1xQuH9kRgB4Z8ewrquD5H7dw+RsqNOKy2ygs9xDlVILq3AFZnDsgi0XbC5j8+iIA7hzfnWcvHUhhuYecwgr++dU6Fm4zEqX3/q5niCLYlFuC1ydJNwm/YJJjXcz581hOfkK9bH8c3ZX7J/RCCMGzlw5i6m+7+fPvevLvWZv4bHk2p/dO542rh6kQzvr9jO2Zztq9Rczfks/NHywHlCJ56pKBAceZPLwDP6zPJSXOzaXDOzBpWAc8Ph9uh91vdavz7MFvOw76hd/EgVl8rimgHunxCCHokBRDYXkRHZJiGNopiVfmbeOxWRuIdtoZ0UV5T0kxgT27Kz0+eqTHBeRCRnY1vEuzwAP8QnldTjGjuqawZOdB5m/J51C5hy6pcfzn4m4AfH7LSTjsAqfdxtWjOvPOLzvZfbCcAe0N63N0j1QuHNKOzftLSI1zc82oTizecZCMhKiQ4wFEu5RQW7A1nw5JMQHtSohS51VY7mFYpyTsNkFitJN3rxvB3E15XPfOEr5dl+vf7qIh7dlVUMYzkwZyyr+VNtI9L4C0OBfB6EaP7j3pPDd5MMt3HaJDcuDv7bTw6bOzN7O3sIIvbzs5rPVtswkSopwUlFVzZp8MpiwO9GTfuW4Er/+8nUnDjMh3ZmK03zu9bGRHf1gtOdYdsv/3bxiB02YLydUlxjRdL//jomdxcxMfH09JSUnYqofS4mLi4hOJiYlh48aNLF68mP0lVX7BW1Tp8bv/NT4f+KBNjJOKchXSKa6qUUlcCPh/sLyK6hofReUeBg8/kZnTP2fg/ffz/fffU1R4iIQoBymxLpwOm7/6JtbloKy6BpsQ/n25HXaKKgxF4JOS0qoahBBEO20M7ZHKBzeM5K6PV3LPmScEnFtmYjSThnXwvwj/PK8Pf/tiLZUeX8BDPKJzMiO6JHN2v7Z+wRIf5aRDcgx9sxLZmFtCrMvOmod+h80mQq7jeq10Lj0+9KUxk2Fa3q9doj9BPrhjEoM16++Wsd3okRHHtSepXugOu2BCf1W1nBgd+KJdPaoTwXROjeXHe8b6vwsBbltoQcBt47pz2zjj++COhkDRhWUb7cVOjXfTV8tLFJZ7OL13BlFOu7Z/4zq2TYgit7gyRLDVRUeTsBveOYnSqhp//Nm8LNplnIPdJvjurtFsySvxJ271tjwzaZD//jz8+371Hv/UHqlKESRHB/xutmz1/JXOyC7JuOw2yqu9JGsW8+UjO3LZiA4B1+OCwe0MRRDm2dCPGbwsMdrJOFMSVic1zo3TLsg+VEGvtvF1hmAKNE/t1B5p/uf/9auGktUmmp5t43l60sCQbV68fDBr9xYF7Ff3CMyYc3dHC0sRNAIpKSn0HzKCXn36khAXS0ZGBgA2ITh57HimT32XAQMG0KFLdwYMHgaopC1AQWk1FR5vwAMe5bTjsAtKKmuQWvzIbhNIVOw+t8pJeZXavsLj5Zrb/8z9t9/AmTOnc9q4sWRmZtKrYwZut5tiUxw7LkopgminnTKtFDLWbfeHH9wOG1U1Pkqr1DoerU1dUmOZftvJYc/97+f0wWETdE+P44LB7fjbF2tDXnqbTfDJH0eF3b5/uwQ+Ww5n9cv0K4/gCqeNuSo+np5QtyJw2I1q6I7J4YVl9/S4AKvVTBuTxfXudcMZ2zNUWBwubWKMF14Xulee2In5W/Lpl5WAw26jX7sE1u4t5tZx3QK2feDsXkQ57bz203YAv1KL7LhO4twOSqtq6NcukXU5xazZq5L5KWGsaHMbzd6AmYZ0NhzTM43HZ22kS2rgNY9y2nE5bFTX+EK8nhiXg+7pcazfV0yyqY36cd+4ehgLt+XTr50RtjIrLJ07TutB+6QYzuzTNmRZOPQQ1I78MkafEHb+lhCGmBR8VpvogDYF47TbQu5dchhF0BxYiqARkFLy2ItvANAvKxGbTcXZfVLicrt579MvSY1zB9Qo+6Rk1q+qeiQpOYV5i5ZRUFpFfJSTe++9l+yD5Rwsr+Zfz75M9/Q4iitqmLlwlX/b7n0H8tanX1Nc6SE+PoFXPviMHm0TWbtiKXPnzvWHkBx2k4Jx2Pzbx7ocRLvsmL3PKKedqhoflR4vKXFuIuk2E+2yB1iGX99xCkkNeLgvG9mRrmlxnKLF/euirtBQMMFufyToHsHwzkmNqgR0/nv5kIC+CL/r25Ytj07AqSmwV64YSkFZdYgletNopRgenL4OgNE9IhNSoIRn+6RoNuaW0L99oj8/Aiqe3tT0apvAB9ePZFjnUOUV67JriiD0eemmKYJwFvMZfTI4o09GQGI1nEcQ5bRz2YiODWrv85MH8cGiXVxez3Z/OasnUxbtJt0UFgunjGrDZbdR7fUFKLrmxFIEjYA5Bl9S6SHW7WBXQbn/t9LKmoDqjHDYBPTMiPcLBT00oH/2ScgL7etCdY2PfTnZ3HfrH3DYwO1y8cYbb/iXO23Gy+7W9ilRLxoQkOiKctr9lTAxTjuHU3tVl0UUDrfDXqf1FeuyU6aFzsK97MHEuOyUV3tDrMxIaBOtXspoV9O8FucMCO047zR5MR2SY+pUYBMHZjFjVY4/jBQpnVNiyS+tom1CVMDxXPaj05/0lB7hlbxeLBHOKu6oeZWx7trvhTmE0hAhXBcD2rfhPxfXX5Vz69ju3Dq2e8BvdXlYwcS47VSX+0gOowSbA0sRNAJ6fB1UjXxpldcfegGo9voC6uN1kmJcZCREkVtUQWqsG6fJQkuIdlBa5SQ51oVNCH+ttDm+r9OnV0/Wr1kVtm26RxDrcuB22EiOdQVYWWaPwW06vlkRNSedU2NZl1NMYrQzojZ9d9do9hwqP6yxkvRknMve8G2PBk9fMpBHL+hXa4e/2rj3rJ4cLKtGCBGoCI6CR1AX+hAU4TxI3UuIdDiHuhTG0cLZAMX6p/E9eHjG+nrDnUeL5r96xwHVmiKIdtoprarxD2kA4LAJanyBgjshyklxpYdol4qTdkwJ7cDlctgDOnbZhKBHehwOu80/7ojuXtZVUia07VwOmxYmCLQ4HSahYhYM7mYWEjpZbaJZl1MctgdzOOqzqutCVzQNeaGPJi6H7bCEd7e0OLql6fsw7ndzn6f+XoSzivVYer+suj3M9knRZB9quqEXIuHmMd1YtquuYdVCue7kLlx3cssZ4t1SBIeJlJKqGh8Om/BbW21iXCHjgbgcdmqCxqiJj3KQ2Saqwa55cMhCVy96KV6k25kxKwLz54ZanU1FquZun9u/6ccj1C3U5haQTYmrJXkEmiJoEyaMN7RTEj/dO7bWpL/Ot3eNDjt21NFE70R5LGMpgsMkr6TK3wsVVCIzLsoBqiCDdknRVHl8eH2S4AEw7TZxRCViCVFOvD5J28Qoiis9R2S92005BFsLHHr6hlO7MuaEtJD6+KZgWCdVuz95eId61jx2MSs5ZzOHwHTPubbKmU5hPOVg4tyOkA5fFg3HuoINRErJpv0l/nAQqCRm28QopJQ4bDa8PklStAtbrPCPR6MLWZ+UYUfbawjmkNGRxkbNOQK9d2NLsohTYl1063d0RifvmBITMODY8Yg5D3W0ksX1Ea5qyOLo0jKehGOIyhqfXwm0iXHROzOBtloJmRCCxGgHMWui31sAACAASURBVC67P7Siy9mkWJe/sqFdurI8c3JyuPjii8MeZ+zYsSxdurTOtjz33HOUlxvVSZEMax2MrqCcdpVD6JQSQ7e08HX2zUFLSAIeT7Sk0NDUG09k8vAOAZ3ZLJoHSxE0kApTvD/KYfMLUJ2sNtF0TQtM8qr/kJHgpovJms/KymLatGmH3ZZgRTBz5kzatGn4gFTmTlaJ0a5mFxCg4q4u7fpaNB7me9vc13ZUtxSeuGhAs7bBQmG9ZQ2k3JSY0l+k++67zz8xjRCChx9+mIcffpjx48dz+qmjuOj0k/jumxkIIYg3JXZ37txJv36qM1ZFRQWTJ09mwIABXHrppVRUGEnnW265hWHDhtG3b1/++c9/Amogu5ycHMaNG8e4cWosg86dO5Ofr0bdfOaZZ+jXrx/9+vXjueee8x+vd+/e3HjjjfTt25czzzyTiooKYlyOZhcKwdw8phubH5nQ3M047jDnBRwtpCDAovk5/vzuWfdD7ppG3aVs2489Ix5UvW5rfMS5HSTFuPzVDpMnT+auu+7yT0zzySef8O2333L33XdTLl1s2rWXa88/k2suu6TW+vZXXnmFmJgYVq9ezerVqxkyZIh/2aOPPkpycjJer5fx48ezevVq7rzzTp555hnmzp1Lampgh51ly5bxzjvvsHjxYqSUjBw5kjFjxpCUlBTxcNcWxydmhW/NS22h07LMwBZKdY2ksMJDhceLlJJYt4OkWJcxqNngweTl5ZGTk8OqVatISkoiMzOTBx54gNNOGs4fLzuf3H057N+/v9Zj/Pzzz36BPGDAAAYMMFzmTz75hCFDhjB48GDWrVvH+vXr62zvggULuOCCC4iNjSUuLo4LL7yQ+fPVGOxdunRh0KBBgBrKeufOnUdyaSyOMVpC2M+i5XH8eQQTnmj0XeYWlOGs9vqHkgiX3Lr44ouZNm0aubm5TJ48mSlTpnDgwAGWLl1KTomH00f0o7Ky7jl4w1loO3bs4KmnnmLJkiUkJSVx7bXX1rufuuav1ccgArDb7QEhKIvjn5YWArRoGVhPRQRU1fiIdtr9g5LFhBnqYPLkyXz00UdMmzaNiy++mKKiItLT04mJdrNn3RJ27doVso2Z0aNHM2XKFADWrl3L6tVqQLri4mJiY2NJTExk//79zJo1y7+NPvx1uH19+eWXlJeXU1ZWxhdffMGpp5562OdvcfzQUkpGLVoWx59H0MhIKfFoeYG2CVGkx3sDhjvW6du3LyUlJbRr147MzEyuuOIKJk6cyLBhwxg0aBC9etXd+/CWW27huuuuY8CAAQwaNIgRI0YAMHDgQAYPHkzfvn3p2rUrJ59sDAd90003MWHCBDIzM5k7d67/9yFDhnDttdf693HDDTcwePBgKwxkYXkEFmERdYURWiLDhg2TwfX1GzZsoHfv3o1+LK9PsrOgjLKqGjIToyMa/fJ4oqmuq0Xz8cP6/dz4nnp/jvfOcxaBCCGWSSmHhVtmmQd1UFZV45+20UqyWRwPNPewEhYtE0u61YF5KGkrtmpxPGA9xxbhOG5yBFLKRq2LrvR4OVhajd2mOoG5na3rBTrWQoYWkeG0PFuLMBwXT0VUVBQFBQWNKrz2F1filZKOyTF0TI5pkSNzNhVSSgoKCoiKinxqSItjA8sjsAjHceERtG/fnuzsbA4cONBo+8wtqsTlsJFd0jpHRoyKiqJ9+/bN3QyLRsaqGrIIx3GhCJxOJ126NM5sP9U1Pia+uIBN+0v4+zm9uWFY10bZr4VFS8A8Q5mFhY5lHgSxKbeETftVJ60B7Rs+kucxyy/Pw0OJUFNV/7oWxyyWR2ARDuupCGJdjppi7PpTujC0U1Izt+YoMvdx9b+yqHnbYdGkWGXQLYzCPfD6OCjOadZmWE9FEOtyiolzO/jb2b39M3Yd81SVwDd/hqrS2tep0cYcqiw+Om2yaBYsj6CF8cvzkLMc1nzarM2wngoT+4oqmLMxjz6ZCS1m8vZGYfFrsOQNWPRy/etWtTKPYMfPkLcB9q9Xn48ma6ZBaQMLHKSE5e9DRcNmotMJUATbf4I9Sw5rP8cMBdtg83eHv31ZvrpPh4unEpb9D3y+8MsP7VD/o5MP/xiNgKUITLz36y5yiyv58+96NndTGhe7NhlOJGGfpvII8jZA8T7I21j7Op5K2Lcq/LKD25X7nLOycdv1v4nw8onwyij1ee+y2l/axqT0AHx2PXzcwLkgCrbCV7fDJ1fXvk7OSvCEH1VWLx9tLw7Ae+fBW6fXfTwpYc9vKoRRvK/udfetVt5nMF4P5Kyoe9uGcnBHZEr05VHw4SR1HjqeStXWSPj8RnWfCveo70XZDQvjzH8aZtwJC58P396D29X/ut7NPUvA5619eSNgKQITheUekmJcjOjSvNr5iKgshppq9bDroSCXNj2m/pL6vFBdZmxjfknqeiC9NYHb1UV1mTq+z6v2//KJ8EwveHmkEgzh+HASvDZabevzBiqlFwbDM73h9TFwYHNkbTgc3jgNFr+iPvt8yqKsLYEe6bUIR2mu+n9gg/pfVWrcBymNe6Xfj+oy1Z4SbbsdPxnreCoNwV+Ura7RjLvCHlbPEdxg/8b4Mfj8PBWG4Nn8Hbx1BjzXT92/2vDWwFtnwrQ/BD5PAPMeh9fHwv51xroNLUrweaHamJaVFwbBU92N71IqoRq8X6/2/dAOo10z74HXTq1dkUhpPHu60C/YqtrwbF/1HIZtoy80/FqqzUEy+yHVZjOVRXBIG5W44lD4fe5coJT1L8+HX95IWIrARFlVDXHuY3gi7eIceKIDPJIGj2bA4+1g7WeAFubSBderp8Jz/Y3tzMK/qg6P4Ks74LGs+gXgwpfUeo+3gx8fBk954PJDO8Nvt+Mnoz3znlDnUpxjCD//9jvqPv6RoluLC5+HF4fAl7eErpO7Rp3jui8O7xi6de31qPN7vB0sflX99sOD8Hh72PgNPNERts1Rx5r9TygxWeVvn6WE0wuDlTcDsHGm+r/u87CHVXkvyQTncuNHXUDrPNpWCXSADTMiO5+SHJVn2vI9bPgqcFmepuwKtilh+d55KkFaUx3ZvgFm3guPZdbura2aqq7Da6MNZWBWSC8MhmXvqM87F2jt2Rp+X6s/Vs/egc2GEfX++fDt/XW38dcX1X0sKzB+s5kq9KuDlMSWH0BqCreyllDf5m+NdZsQSxGYKKuqIdZ9DHet2B9m5rKVHxrWYnWZcvPz1kF5gSoX3TI7UNDWFRpa/6X6v+hlmPkXFZ4Itv7K8uH7vxnfN38XaMkB5GsW/UdXwLcPqM8HTcK9qgQWPKs+z30M9i4P3L6sgXH1tZ/DY+2V5ayzaRY806eWDbRz0sMZugfy8ZUw79/qs96mLbPV/9WfwCNt4dEsJcDroyRIEQCsUPNRsPAF9f/nJ9X/DV8bv+vbZfSH/WthyVtKCGcvUYJVTzp6q6Fwd9hDf3VJGzJkPoy5P/A8wbBM13+plMzmWYEb60bD9nlKSVUcUspCNyxccTDrvsDnKEorw64sVApq1y/qGVz+v/DXZuZf1LNhZulbxj7M6Ba7blkf2Khi8hD6nOg5ILs2inB+LZ7lds0g2fg1OGOM3397Pfz6Opu0a6Vfz2l/MNqt8/OTMPVy2PStCjnFpEJSZ1jyJnx5m7He7kXweAdlVIEKWXrqnpDqSLAUgYnSlqIIfF6Yfpt6aH78V+TbFWwJ/a0k17DIq0tDrb+fn4SKg8b3YI9gzTT49q/qc0Zf9X/z9/Dba7B+uvoDFZL49FpDEJ2nPcCxaeAJ8iD0F3Dj17Dov8rKyzYlLff8Bj4tfLRvVWh8WY/X6myfpyxGnZ/+o4S/ztxHobrEsAB9Xpg6GYr3EpbVH8PCFyFfu54l+9QxN8yAeY+p9urts2keZM5KzbqThiCpC12g+zyGVVhdqhSpjn7e5vMvyVXC9oyH1ffv/24sm/0QZP8GfS9Q32vxvAbEaZZpjzPA5lTKZPZDSuG9NlotcyfCnsXKYDCTr13DOY8qpbB3ufJgdM59VrVRV2IA0ZoiqChU99kZC45oKAwzWZPPp56tjZryW/qO8g7N1+STa4zvukKuKgZ3gkq65m/S2hok6JO7wuyHwy8v3A0fX6WMEKGJxa0/1h7C2vKDumYAqz+FN8Ybns+Ui5QXt/az0O3mPAKbvoEV76vv57+ilAHAyg8Moy1npTqnE2+FYderEFdtXkMj0AKkXsuhrLqG9PgWML5OwVZY8YHxffw/jM+HdinLY+QfIXj8o3AWTnGOoQgqDgUKGoA9iwxLFFRM86cn4aQ7lBCY8ScloDwVxv6zfzPWz1kOfc+Hn59SYZJ1X0BiBxh8pQoTHNgUGkpa9REUmYRwzopAq3/GneCKh27jlBUXnJw7uF0J+5TuymKbeqn6PaUHnHCmEvwAcRmw5hMozTOOs/FrGHBp6HUKxixgy/MNhaefsx5D113/6lKIToKELKWQpYT5T8HAy2DbXEjvDe1NQ8GbQzy6N1Rdpq5XMDmma1OcA/GZkDVYffdWQc9zlHBZ9F9oPxxG36vuQ22ek67so5PUvvLWqb+ivYFexMdXgd2lvAudgi3QfqjxvXC3EmR60rPP72HZu0qZ6+jXaMEz6n9qD6UEwgnZYKX/dVCu46PLocZkGZfmKkG8Yz5EJYIjylBepUFzhPu88MtzpnMxhYamXa+e66HXQpF2DQ5sVPsMx5SL1f/TH4LVH8HewDlSmPtY+O10Nn4DbQeo53X+08bvn90AMSnKCBE2OPNfSqEsfevIclL1YCkCE6WVNXRNbaRLUlmktHrXMZGtn79FPaixqUZcUKe6TFlZlUXw3QOw+1f1ACV3Dd1H++HQ6xzDWqk4aIRmSvOgLC/02CtNSmfZu+q/zaaEsy4E9PiqsIHU4rSueOPhdMcZ++h+ulJScemwc35oaKg0T5Wz6uz+VQm7qER1jtIHI25UluSGr0It9zWfhJ4DwKx71Z/OL8/DFlPp4HcPKCEY1YAe4x1GKsvYHO7JXWNYbnpFVnWZiien9FDnc3C7sv7mPGJs99dscMer89evMxjCr7osUEGAEvhm4XhgI8S3hZhk6D1ReUxj71eKqHQ/THwe4tqqdc3JUClVmK77eCO8405Q+9IFX42p0kgvIx58FfQ4U4VFdi00jAHduCjYanhHAA638gLNnqcuuPWwU/fT1fOsK4ItsyEhU3kMexYb23k9gc+beV86ngr45h71OaOf8pZ0RaCHp3RFGVzRlLvW+KwbN+aQWnlBoBIMR01VqIcK4aundGLTlJJOPUE7jsk4y16qjuvzKIVgsxt5iuAcQyNihYZMlFZ5jyw0dHC7ETP/cLJKipmrTqQ0YpmgHpZyLSzz0jBVUfPa6EBXG5Rl/eIQeGOcUXGzcWagRXVwu7LCMgcqYWNGF6RleUYyMRxxGcbn3YuV9XzK/4O2psRyr3PV/wteh5gkQxGYk2K65Rubpl5+czJ69L1w07zA4xZsUYKj0ynGb0mdlGcBhsvdEGyO0Bi5bgnXFhIKQSilCkpApWuhsZpKw03X73d1qRJCqSdA0Z5QgQ4qjwDwqxY206+lnrz0hFEE7YYGfj+w0RAgl34Ad62BzAFwzVdw22IVvotOAmEPVPq7FynPafZDRtujEpQA1gnOxQCc+xz0OQ+u/VoZHvlblFeyXxOi+ZsNQZimVdPEpChhVl2ulF5wsUBsulIYNVUqzDjlInjlJJXwNodTNn8XqATCYa7SiUpUCrJ4n/JudGF84WuQ2DHQQ+rxOyjOVs+5Obmbt16F1FzxgFTPzNi/QrfTwh8/d21giKvdUBXKOVBHmfTgq9R//T7qXvptv8GfNxnH0vsW+Kv+jlFFIIQ4SwixSQixVQgRknIXQiQJIb4QQqwWQvwmhOjXlO2pjyOqGjqwWVUm6PH03QvVf3PVyZI34fkByqIE+O9I+E/QYHnhhNSn1xqfY7V44vd/U2V5OotfU1b4qfdoD7G5bZuUlRifqR7+2tAFL8BWrUqhxxlw089G0ixzIPyjAAZeqgSfbqWUm/IMWUO0tqap/4U7jWU2Z+BxotooBVZdqgSa/zzToU0n9bk0qGooEtzxoYrAEa3+R1IHPuZ++Ose6DZefZdeSNP6l3jKjQ5d+vlXl6nrkdJNfQ9XN7/2cxUDP7hDKd1J76vw1j5T34jifYEJynRTQtumeR+n3lN322029ZyYBZ9u7W/9USlmR7QSxtGmYVSK90LPs5UXBMoat5sUfGoPpQj0CiVQgrQ8H077B9y2SP0Wk6IMgA8nwVM9Qj3Ctv00RVAZGBaRXkPBAHysJYyDn2czZsWpK4KCLfBsH+0eCJWTcMUaoaIJT8IpWsjp7TPVe6nz4/+p/51OMn6LSVH3Nhxvnhbopbjj1XUyM+wPcMOP6rMzVoXPwDCwepyp/idpskBXzjEp6r9+/k0YGmoyRSCEsAP/BSYAfYDLhBDBZRoPACullAOAq4GmLZatA69PUuFpoEfw35Hw9gT1WS+ZW/xKoFAEWK8t08MLulegC/1I5lHQBYI5Abjb5EaXFyhBn5AVGKYB9WLEpSmXHAKtdzMxpv4T0qfWy+inBItDy51EJRrCwRVrWCnmpKIuMOPStTabLCYh1P50uo5RVhioOLpObBq0MSkM//YmRX3qn8OfByhBZE5Sp/eBq7QEciSKILG9eqkTsozfUror4eipMMIcutVZXaquR7z2EucHJe67nw67FsD7v1f3UL+ueqxfpzhbhWt0zDHqG2bDPZsgsV397Y9NDwwN6ffp4DYVMtH3G9xRqU0nlRcAo7pGJ7WH6vdQsBW6jIGJLxghpKTOxnoxKYBUYUFQHlJSZ9X225epvInuEeSZKt0StGHPO44KPG6noO9mzPfSnWAIT1AVSu4EdZ1dsUZ1VlSiMmh0zPk4gHbDYJSpgicmWe0HlGcRDj0c5443LH2Aq6fDWf822tV9PGQNUtehpyY7znsR7l4HDu2668+Q7tkf46GhEcBWKeV2KWU18BHw+6B1+gA/AkgpNwKdhRAZHCWklMxYlYPH6yO3WGn1uIYoggMbleW/8kOYY6ruMVfAgCFE9RtZsg/eNPXorK0ziZnh1xvHTOutHjxzyEW3SCG89eKMgXZD6j5GcGIsvQ84tbY7NKFgjq+7Yg0rpfygetn/8J1RSaN7BHoiUW+HGXPowyxM4tLUy6NXcOhusjlMVZeA0NGvfZuOSrhDZKEhXYnFJBuCMamTsqTDKgItR6Cfc8G2wP2d8zQMvFwlv3NXG0ouIUio71sN8Vlw2xK4eUHgvYxOClQSdRGbGhga0sNi3mrlKej3OvhZadPBOF9dMOmYBdzgK43QFijPUcdsUOjnFJuu2p7aXRkDdrdSEOYqtRNvhknvqUoZnTP+FZoLMxPgEQQpAjCEqTvO8AjccepeXfmZOv+i3ao9+rPW5zxDGAOk9TKMq1RTJzYzGZqh5k6AzqYQZ/vh6jomd4HLPoILXjX2oxd7OKOMZxOMY/u0qXJ1RTDtOqOsupFpSkXQDjBnUbK138ysAi4EEEKMADoBIbOhCCFuEkIsFUIsbczJZ+ZvyeeOqSu4++OVnPzEHIDDyxFs1dy+yR8CIrQTji5MdaGx9cdAZVFXPFFHj0+DsqIHXGL0dgTDIoXAHIH+ojtjoK1mBekPWDC61aNjrq7Rk6JRpnVccSrJNv8ZlZRuOwA6nmhqc28VztDHehnxRxh+g/p84xz4/cvQfoSxfhuTtRWbphSKHrrQBbMzWlmiN84NfFlrQ1ccrjhDKZTsCz3XYAGih+DAsNpj09TxPeVGnN0cGnLHKQUGoaW8SZ3h/JcNi1I/1+igxPWhHUpgpp2g2m6+l8FKtC7igjwCs9Gwba6hCMb91ehPACpMoSt9R1AFnflepfaA2BSl4K77NtCICFYE3ip13cw4oowwULzmdbkTVNjErByHXG0815mD4PKgwdnMSl3K0EIA/Xl1xRkhHP2d6H66CoWB8vb0fER8pnEfAVJ7GtvEpoc+OwMvg86nqs/Cpq7fzQvgzEeMtoPyAMzfa0N/rvVEtXmbJhpqoimrhsKN2hYcA3kCeF4IsRJYA6wAQqSUlPJ14HWAYcOGNdp8lF6f2tXXqw2rokEegc6hHUa1TuoJofXDjigVG9Zj1sEWaXBtfzjMlmBsqooxe6tg5RQVVy7YboRkzMKjTUflfjtjlDvcf5KyWGbcGXoMs5AfMFmVqOroYQLzC6+/HD8+rEoIg136qETocqqqqQb1YuhWZruh6s/8YAd7G6A8gfIC08snYKhWRx4cggtH1hCldN1xhoDzVquXzWyNxmUEhrdiTIrgglfhu7+p83PGBHkEpcZ/V5xqp92lrE9hg/NfNTwiIVQepGi3Efc1x+h1zMrUHOZzNUARxKQGno+uCBzRKl+g3+uoRKUMfDUqNp3aw1D6waGhNJNHkKJZxrpiDzh2SuhvwUrM7G1c8g788oIqQ4bA5zAqEU68TY1Rdd4LgQoaAr1pb1VoHN3vJZuEqfmaDpys+hUMmAzfafm9+LaBz6LdYWzjcKvzMz87Zz8Fa7WB6XRl0rZ/oPfaEPT3168ITO2NTQtdvxFoSo8gGzAHedsDAcFZKWWxlPI6KeUgVI4gDWji8QMMyqtDtavTfhijjuasNEIXmQNDqyQcUUowmEvuzOjJY1CJLN260BlxU6D1a06kfnWH6uRUnG08rOYHR3erXTHqgb7ojUDX1YwubOOzVKWFLhDAZCWahIP55SrPDy8AuptCBsGhBlBW/7DrlSUabl5o/RgdtQTmyX8ylkUnqb/gig5zHkFPvNkcgRZucFvHB1VqmRVvcle4bKoSUM5o1WFMr5Sp1sYI0j0yIdT9ASXEBl6qBK3OmL8oodh9vHEOOqPvVfd+6HWm8zfdS0eQVV0X0UkqR1JTrapS9q1WncT0EE5wGHD8PwyhXltoCFQFTbuhoZVpZsIqgjAeAaj70n4EXPah0SbzvoVQnsdlH4YqgWDL3OsxEq8DL9d+1OzGAEVg2q77ePjjzzDKFI6Kz1LHbdsfTrlba6/WfrszTDvijER+Y1jseq7Mf2zTfdA940amKRXBEqCHEKKLEMIFTAYCBiERQrTRlgHcAPwspTxqA+KXVBr1zxP6qRc/PspZ2+qBmBO80ms8/GarScfuDAz/BCuKNZ8q6+tvuTDyJlWq10XrfzD8Rjj7SRVe0o+R3DV8mEAXGmaLJ1Mb6MocDgp+KXX8bnQY93XAJPU/ziQgg9cLZ93qXkpdnPsMXKG5/PFZgYJcF0qJHeGhIuh5lrFMCLhvJ5wU5N3ouYbT/mFcE+kz9hXc1oeKjMRd99PVd0eQNazjjFZDOsQkw6ArVLiv4pB6BvTroYcVwnVGyhwIf9tnVBeZLc/T/q7uvblSxywUbQ14XfWQU2UhvHKyGioiKtGI69fWUQoMTyDYIwDVZ+HGOXUfO5zVGuIRaPt2xYWeV7CAr41ghdPtNBV7f6jIMA6Cw0HBn8MRr6Upb16gOoyB8f7YHIHeoo5egCEbQRFEt1HnoJcum4ltGkXQZKEhKWWNEOJ24DvADrwtpVwnhLhZW/4q0Bt4TwjhBdYD1zdVe8JRUqlu7qAObXh+8mDuyCulT1aED2HwCJp6XDQ1jCLIW68GrQIVQgpOJnvKYcx9gQJat5icJiv29qXqxU7uGtgZRkcXRE6TgG6nxbfNVSzhlEhyV2Uxmvdj5qQ7Ycg1gTHtYKsw3Hbhrkdd3LmCgAiiLjCCK6HMBAvtxHaqwiY6yegI5/MqxeGIUsLBHa9i0eYw3V/31q4AdPRrl9xVhZOqSowSYH8cWROEkQi0cMrTTF2WdyT7rSg0ym/tTtUR0e6qW6DonmB916I2nNHQ/xJl4LQdoJLjwcaH3aQIwm0fCTEpKizrioO71wZeS10Z631tzMep7VlKPUH1iwh3zc2KIDaMx6PnfMyVb01BsDfSSDRpz2Ip5UxgZtBvr5o+/wr0CN7uaFFS6UEI+PyWk7DZRHglsPk7+PQ6uGdjYOwy2KrXrZOUek4na7ChCC56Sw08BSqRasYfijG9FDHJhsIJ97LogthsYek1/eYwj1kR3PCjekni0o12hXsRhAhNbAYL/nCKILgqpj6cQQlK3Yqvy4oLtlztLuM66ZUguqWm16+74pTFZ661r0vZ+NunXffoJHWdzBag3kZzYrs+6lMEwQnbSPGP72OKoZfnq+PdOCewL0cw/tDQYSoCULmRodeqxHTu6tB9+T2CMM9MuBBhOHShGNUm9DrqytjvEZiO4wxzTFAVb6V54Zfp735sWuC7pNNpFPzh+8BhRJqCJsoRtOohJoora4hzO2qfjWzev1X8HVRc31x+GTzxhzlsUxfmF9BcfhdsZeglmMGCUSecgDALy8lTlYUTkwwXv608Ef+2phCJ+cGNqsMjCIc9KIYcTvA1JJwRDl1g1CUcgmPZZsWgt1EPNzmigCJ1jmbFGilmRRC8rZ7M7Xuhqk0P7ksQjmDlGkykQjFkv5pgnGqq/NITxvUlMf3J4jA5gkixO1QuSu8VHjzkQl2KAOCyj+t/l4IrygKWBRkC5uPU9kzW9TwMvlp5lUOvVZ03AUbdHlhZp+exmpKGFAw0gFauCDwk1JYTqKlWg4bpLHkT7LeqXpGeisB+A2AoAmeUik13PFEliL+5J9AqM8c1HW4VFzaX5QVTm0UY1iMwKYJeZxuf+11U+/7NuOvIEYQjeNCw2sobL3qr/jFbakMXSnVNZBIssMwWW98LVc/l07RB5OwRhJrqQj/HqDah4RW9Sqf7eJV8TosgTFBfvPpwiQrjEURKuMKAw0UX1sETHtUX8jPngmpDvxfmTn868W3h5LsMQd3hCIW03aHGvwLDE+k9MbA3/DFMq1YEJZU1xEdpl8DrUTHNhCzoOlaNxmgWXiunqL9rv1HDHq+cErgz80sz2tTjNW+DzuMriwAAF85JREFUMSTv+AcDFYEQqlIkHHoyukGKIEIBXht1JYvDEewV1aYI+l98+G0afa8aKqDruNrXCVEEpu/OKJhoGnFSN7AP91rp3kd0Uqib3tOkfOsbBsLfniaaGztcyGniC5Ftq18/W4SFE3Vhnosg4Bh15Ajq4+ynVF8d/R0I18lOCGOoblAdvsbcH34MqIbSYYTysBua/zoSRt9b/1ShR0CrHnSupNJjKIKd89WYQO9pnZ/DDcAF8O45gePIDL1W/a/todCF48DLlXAIV1pXF7XFmcOGhhoi3ERgaSeYPIIIE5RdxwYdvwnc1rb91cBq4RJ0OiHx5zpCGnp53+Fa4nqRQHRSYKejO1eEt0wjweYIvRdm4jNV0rUhBFcF9b/E6H9RH7pH1RhKSg9DBQ/9rT+/h+N1jLhRDbKnty/S3tbj/qr6IhwpyV1VMUJDw4pHwml/h/P/22S7b/UeQUaC3tvUNHa5zxs4Bnww5gnW+09SIzTW9tLoglx/4CN9ePT91RanDXe8SKstAB4KM8mFK05VDkX6YnUYrhKur2r9EhrS87UxCZcsrg1dkB+uR6AnH6ODQkPRRyAUHiyoe/k9EfQ8D8ZmD/zekKSzPYK8TKTEZ8A/C0P3pSvr2sa9igQ93HQk194CsBQB3dO1S2AeE9xTAXtXqIc03HAM5koTZ1TdL4y+vf4iNtSKaMjLWNvQEZFis8EtvzSsMsEs/JtLEYQki+vyCHRFcJgeQY2pt6fZA6qrLr8l0BAjwX/9GilsFe4Z9ncoO4Lwkz4CbH0Jd4t6adWhoWJzaMg8c1d5gRpl0VxpUxv1CT/dgtSrf9wNFBiRjEyqh3REI9zONh1qr1QKh9nSbKKKhnppiEdwpKGh4Pup01Sx/iPB3PGrQR5BI+QGIj2G/QhsUd3raWi41SKEVusRVG74njOqfiAzUavfNyuCPb+pnqgn3aGSlHoJaTjqs7T0Caf9FlCEwjoSBaBz9lNqPJsev4t8m8bCfP7NFhoKElx1KoKgER0bil69FK7XbUuj3VBI7qaGnm6IIvCX7DahnRg81efhMOE/ajDGzqMbp02tmFarCKI+voQnnfBVsjaehzk0pE8UktFPdfNO6qQmrAg3fHF9wm/kzSqnMPxG47dT7wmccORIiW+rxrRpDsyK4Ejqzo+EkPhzHUL6SHME5z6rnoUOWsnvOc+Edi5sSeiCtiFenq0Rk8W14e+pewTeR1w6jKml6s6iQbRaRaDTIUkTZGaP4MAm1QFJ7xU7cLIaefL5AUo5JGSp6SOhfo8gLg2unBb4W/AAZ+EYfj2s/zJ0RM9wNCT+29iYLc2WEh6pK7ShC6DD7UeQ3ksNgKYz/KiOitJwdKu+IQPWHY37qCvkI/EILBqNVn8XOiRoccbyfG3o3nw1LG1iu8D4ZVInNRCUzkNarL8hL1hD6DI68Hh1cbjDEDQGLUX4m6nTM9FHo2yijlwtDV0RNMQjMDZu1KYEoCvkI8kRWDQarTpZDJBi08aTLyswZgkq3F37lHQ6en10S3iQmys231KJJER1pJ3vjhUOxyPQx9RvSiWfpA2jnhrB6LQWTU4LkGLNiyg/qOqQq0uUItDzA23qUQTXfA1FdUwEfzQ5LGvvOKYuRRCXoYb+aCpPrqWhC/PDGi6iCRVB3wtVR7lIQp8WTU6rVwSUFxh1yGbhX58iiG7TcuqXW4tQi5S6cgTX/6B6hh/pYHjHCv55cRviEcjAbZsCIaDTSU23f4sGYSmCioNQpsX7AyaQzmie9hwOzZksbpHUIcCSOhlhidaAPzTUEK9RL11ugfkfiyahdSoCn8/4fHCHmsYPAoeIDjcLUUulOZPFoGbqqm9c/aZm4GWwamrztqEl4k8WN8BY6DZe9S4/6Y6maZNFi6NVKoKK8lL8r8WPphEK25gVwTHQW3HETfDb680f5jj/5eY9PqgJ5qUPVn/c3C1pYYig/xEQlwb3bq1/PYvjhlYSKA3kYGGYAdcgyCM4BhTB2U9GXmLaGjgase1jDf8Mbb6617No1bRKRVBYWMtkHWbhfywoAguL+kjVpk493A50Fq2C1qcIPBWc8NVEAMoyguYXNVuSzR3ztjgMrCRnCGc/paYtrW96SotWTetTBLlrcVarcErF0JvhlLvDr9cSOopZHB5WaMjAFRM4bamFRRhan7STXv9Hd0IajHhIdWzRxz6xOHYZ9zfVWeyECOa7tbCw8NP6FEFlsf+jI0abknHkH5upMRaNSnIXuGZGc7fCwuKYo/WFhqoMReCKqmVu3rhjqDOZhYWFxRHSCj0Co9zS7g4zWNsD+5p2Qg4LCwuLFkbrk3iaIrhR/j1wSAkdV4w1iJuFhUWrovUpgqpivNhZ4RjY3C2xsLCwaBG0PkVQWUyFPQ63s/VFxSwsLCzCEZEiEEJ8JoQ4R4jjIHheVUyFLRa389g/FQsLC4vGIFJp+ApwObBFCPGEEKJXE7apaaksplzEEuWwN3dLLCwsLFoEESkCKeVsKeUVwBBgJ/CDEGKhEOI6IUQds4C0QKqKKRMxlkdgYWFhoRGxNBRCpADXAjcAK4DnUYrhhyZpWVNRWUwpMZZHYGFhYaERUcZUCPE50At4H5gopdynLfpYCLG0qRrXJFQWUUJbyyOwsLCw0Ii0dOYlKeWccAuklMPC/d5iqSqmWFoegYWFhYVOpGZxbyGEf6Z2IUSSEOLWJmpT0+HzQVUJxTLa8ggsLCwsNCKVhjdKKf3TekkpDwE3Nk2TmpDqEkBS5IvG7bAUgYWFhQVErghsQhiDvAsh7ICrvo2EEGcJITYJIbYKIe4PszxRCDFDCLFKCLFOCHFd5E0/DLSRRw/5oolyWqEhCwsLC4hcEXwHfCKEGC+EOA2YCnxb1waasvgvMAHoA1wmhOgTtNptwHop5UBgLPC0EKJeBXPYaCOPHqyxPAILCwsLnUiTxfcBfwRuQc0D+D3wZj3bjAC2Sim3AwghPgJ+D6w3rSOBeM3biAMOAjURt76haB7BQW8UHS2PwMLCwgKIUBFIKX2o3sWvNGDf7YA9pu/ZwMigdV4CvgJygHjgUu1YAQghbgJuAujYsWMDmhCE5hEUS8sjsLCwsNCJdKyhHkKIaUKI9UKI7fpffZuF+U0Gff8dsBLIAgYBLwkhEkI2kvJ1KeUwKeWwtLS0SJocHm0I6hJirByBhYWFhUakZvE7KG+gBhgHvIfqXFYX2UAH0/f2KMvfzHXA51KxFdiB6rjWNOiKQMZYHoGFhYWFRqTSMFpK+SMgpJS7pJQPAafVs80SoIcQoouWAJ6MCgOZ2Q2MBxBCZAA9gfo8jcNHDw0Rg9vqUGZhYWEBRJ4srtSGoN4ihLgd2Auk17WBlLJGW/c7wA68LaVcJ4S4WVv+KvAv4F0hxBpUKOk+KWX+YZ5LBGdRjLQ5qcJpdSizsLCw0IhUEdwFxAB3ooT3OOCa+jaSUs4EZgb99qrpcw5wZqSNPWKqSvC64qFc4LRbisDCwsICIlAEWn+ASVLKe4FSVFz/2KSmEp9dzUfsshSBhYWFBRBBjkBK6QWGmnsWH7N4q/HZ1PQJTitZbGFhYQFEHhpaAUwXQnwKlOk/Sik/b5JWNRUmRWB5BBYWFhaKSBVBMlBAYKWQBI4xReDBp02o5nIc+w6OhYWFRWMQac/iYzcvYMZbjdfvEVjloxYWFhYQ+Qxl7xDaKxgp5R8avUVNibcar9BzBJZHYGFhYQGRh4a+Nn2OAi4gtJdwy8frwSvUKVs5AgsLCwtFpKGhz8zfhRBTgdlN0qKmxFtNjYgGsPoRWFhYWGgcrjTsARzBMKDNhLeaGt0jsMpHLSwsLOD/t3f/MZaVdx3H3x9mFgRBftilNizhR6VG1JbCio21Fa2mlKpAUiOtrY1RSZPW0JioEKyo/ymx+g+GNpUUUyxVS4U0BIq03Qaj8qtbhALtFqVsirJNKQqBnZl7v/5xz8zcuTO7e0HO3oHn/Uomc88zZ2a/95vs873Pc57zHKa/RjB6xuOq/2L0jIKXlsHiaiFwRCBJwPRTQ0f1HchBMVhgaYs3lEnSuGmfR3BhkqPHjo9JckF/YfVkaYGleEOZJI2btje8oqqeWj6oqu8CV/QTUo8GCyzUaBC0Zc7lo5IE0xeCjc6bdunp5jFYYDHzHDp3CC+HrZMk6cUwbSG4O8mHk7w6yalJ/gK4p8/AejFYZLHmHA1I0phpC8FvAwvAp4C/A54F3t9XUL0ZLLDIvEtHJWnMtKuGngEu7TmWflXBcJGFmvdmMkkaM+2qoduSHDN2fGySW/sLqweDRQD21pyFQJLGTNsjvqJbKQRAVT3JAZ5ZvOkMFgBYqHkOc2pIklZM2yMOk6xsKZHkZDbYjXRT6wrBXpwakqRx0y4BvRy4I8mO7vjNwMX9hNSTlakhLxZL0rhpLxbfkmQ7o85/J3Ajo5VDLx2DvQDsHc6xZYvLRyVp2bSbzv0mcAmwjVEheAPwL6x9dOXm1o0Inqs5RwSSNGbaHvES4MeBR6vqZ4DXA3t6i6oP3TWC54auGpKkcdP2iM9V1XMASQ6rqoeAH+ovrB4sXywezrnhnCSNmfZi8e7uPoJ/BG5L8iQvtUdVdlNDzw6cGpKkcdNeLL6we/lHSb4AHA3c0ltUfVieGqpDnBqSpDHPewfRqtpx4LM2oa4QPDuc5wgLgSStaKdHHJsacvdRSVrVUCFYnhqaY95CIEkrmisEzw7nmD+knbctSQfSTo946jnwW5/n0cFWp4YkaUw7heDwY+GEs3hmOM+8F4slaUVTPWJVsTgothziiECSljVVCAbD0c7ZjggkaVVTPeLSSiFwRCBJy3otBEnOTfJwkl1J1j3zOMnvJtnZfd2fZJDkuL7iWRwMAdjiqiFJWtFbj5hkDrgKeBtwOvDOJKePn1NVV1bVGVV1BnAZsKOqvtNXTEsDRwSSNKnPj8ZnA7uq6pGqWgCuB87fz/nvBD7ZYzwsDkcjAq8RSNKqPnvEE4DHxo53d23rJDkCOBf49D5+fnGSu5PcvWfPC38MwvKIwFVDkrSqz0KwUW+7rwfe/yLwz/uaFqqqj1bV9qravnXr1hcc0OrUkCMCSVrWZ4+4Gzhx7Hgb+36GwUX0PC0Eq1ND3lksSav6LAR3AaclOSXJoYw6+5smT0pyNPDTwI09xgKMjQhcNSRJK5738wimVVVLST4A3ArMAddU1QNJ3tf9/Oru1AuBz1XVM33Fsmx5+airhiRpVW+FAKCqbgZunmi7euL448DH+4xj2fINZU4NSdKqpuZIlpZHBE4NSdKKpnrERW8ok6R1mioESyurhpp625K0X031iKurhhwRSNKypgrByqZzjggkaUVTPaLbUEvSek0VgkVXDUnSOk31iCubzjkikKQVbRUCt6GWpHWa6hEX3YZaktZpqhCs3FnsiECSVjTVI7pqSJLWa6oQrE4NNfW2JWm/muoRl9yGWpLWaaoQLA7dYkKSJjVVCJYGQ+YPCYmFQJKWtVUIhuW0kCRNaKoQLCwNvVAsSROa6hWXhkNHBJI0oa1CMChvJpOkCU31iouDcnsJSZrQVCEYTQ019ZYl6YCa6hVHU0OOCCRpXFOFYHHgqiFJmtRUr7g0LLbMOyKQpHFNFYLFwdDHVErShKZ6xaVB+ZhKSZrQViEYOiKQpElN9YqLrhqSpHWaKgRLwyFbvI9AktZoqldcGpTPIpCkCU0VgsWBIwJJmtRUr+jzCCRpvbYKwaBcNSRJE5rqFUdTQ44IJGlcU4XAqSFJWq/XQpDk3CQPJ9mV5NJ9nHNOkp1JHkiyo8943GJCktab7+sPJ5kDrgJ+HtgN3JXkpqr66tg5xwB/BZxbVd9Mcnxf8YBbTEjSRvr8eHw2sKuqHqmqBeB64PyJc94F3FBV3wSoqid6jMcH00jSBvrsFU8AHhs73t21jXsNcGySLya5J8mvbfSHklyc5O4kd+/Zs+cFBVNVPqpSkjbQZyHYqMetieN54Czg7cBbgQ8lec26X6r6aFVtr6rtW7dufUHBDIajf9oRgSSt1ds1AkYjgBPHjrcB39rgnG9X1TPAM0m+BLwO+NqLHczSSiFwRCBJ4/r8eHwXcFqSU5IcClwE3DRxzo3Am5LMJzkC+AngwT6CWRwMAXxUpSRN6G1EUFVLST4A3ArMAddU1QNJ3tf9/OqqejDJLcB9wBD4WFXd30c8SwNHBJK0kT6nhqiqm4GbJ9qunji+EriyzzgAFoejEYHXCCRprWZ6xeURgauGJGmt5gqBIwJJWquZXnF5asg7iyVprWYKwcqIwFVDkrRGM73i8vJRVw1J0lrNFILlG8qcGpKktdopBMsjAqeGJGmNZnrFRW8ok6QNNVMIllZWDTXzliVpKs30iqurhhwRSNK4ZgrByqZzjggkaY1mekW3oZakjTVTCF75fYdx3o/9AEcfvmXWoUjSptLr7qObyVknHcdZJx036zAkadNpZkQgSdqYhUCSGmchkKTGWQgkqXEWAklqnIVAkhpnIZCkxlkIJKlxqapZx/C8JNkDPPoCf/0VwLdfxHBerszTgZmjAzNH0zlYeTqpqrZu9IOXXCH4/0hyd1Vtn3Ucm515OjBzdGDmaDqbIU9ODUlS4ywEktS41grBR2cdwEuEeTowc3Rg5mg6M89TU9cIJEnrtTYikCRNsBBIUuOaKQRJzk3ycJJdSS6ddTyzkuSaJE8kuX+s7bgktyX5evf92LGfXdbl7OEkb51N1AdXkhOTfCHJg0keSHJJ126exiT5niR3JvlKl6c/7trN04Qkc0m+nOSz3fHmylFVvey/gDngG8CpwKHAV4DTZx3XjHLxZuBM4P6xtj8DLu1eXwr8aff69C5XhwGndDmcm/V7OAg5ehVwZvf6KOBrXS7M09o8BTiye70F+DfgDeZpw1z9DvC3wGe7402Vo1ZGBGcDu6rqkapaAK4Hzp9xTDNRVV8CvjPRfD5wbff6WuCCsfbrq2pvVf0HsItRLl/Wqurxqrq3e/2/wIPACZinNWrk6e5wS/dVmKc1kmwD3g58bKx5U+WolUJwAvDY2PHurk0jr6yqx2HUCQLHd+3N5y3JycDrGX3aNU8TuimPncATwG1VZZ7W+0vg94DhWNumylErhSAbtLlu9sCazluSI4FPAx+sqv/Z36kbtDWRp6oaVNUZwDbg7CQ/up/Tm8tTkl8Anqiqe6b9lQ3aes9RK4VgN3Di2PE24FszimUz+u8krwLovj/RtTebtyRbGBWB66rqhq7ZPO1DVX0X+CJwLuZp3BuBX0ryn4ympH82ySfYZDlqpRDcBZyW5JQkhwIXATfNOKbN5Cbgvd3r9wI3jrVflOSwJKcApwF3ziC+gypJgL8GHqyqD4/9yDyNSbI1yTHd68OBnwMewjytqKrLqmpbVZ3MqN/5fFW9m82Wo1lfTT+IV+3PY7T64xvA5bOOZ4Z5+CTwOLDI6NPHbwDfD9wOfL37ftzY+Zd3OXsYeNus4z9IOfopRsPx+4Cd3dd55mldnl4LfLnL0/3AH3bt5mnjfJ3D6qqhTZUjt5iQpMa1MjUkSdoHC4EkNc5CIEmNsxBIUuMsBJLUOAuBdBAlOWd5B0pps7AQSFLjLATSBpK8u9trf2eSj3Sbqz2d5M+T3Jvk9iRbu3PPSPKvSe5L8pnlveWT/GCSf+r26783yau7P39kkn9I8lCS67o7maWZsRBIE5L8MPArwBtrtKHaAPhV4HuBe6vqTGAHcEX3K38D/H5VvRb497H264Crqup1wE8yuqMbRruZfpDR3vOnMtqPRpqZ+VkHIG1CbwHOAu7qPqwfzmhTsCHwqe6cTwA3JDkaOKaqdnTt1wJ/n+Qo4ISq+gxAVT0H0P29O6tqd3e8EzgZuKP/tyVtzEIgrRfg2qq6bE1j8qGJ8/a3P8v+pnv2jr0e4P9DzZhTQ9J6twPvSHI8rDxf9iRG/1/e0Z3zLuCOqnoKeDLJm7r29wA7avT8gt1JLuj+xmFJjjio70Kakp9EpAlV9dUkfwB8LskhjHZqfT/wDPAjSe4BnmJ0HQFG2whf3XX0jwC/3rW/B/hIkj/p/sYvH8S3IU3N3UelKSV5uqqOnHUc0ovNqSFJapwjAklqnCMCSWqchUCSGmchkKTGWQgkqXEWAklq3P8BUIF2zIxaNvsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient-Boost Classifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "acc_gb = accuracy_score(y_test, pred)\n",
    "print(\"Accuracy for GradientBoosting:\",acc_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"knn.pkl\", \"wb\") as file:\n",
    "    pickle.dump(knn_clf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accuracy = [dt_ac, knn_acc, lr_ac, rf_ac, svc_ac, gb_ac, np.mean(history.history[\"val_accuracy\"])]\n",
    "models = [\"Decision-Tree\", \"KNN\", \"Logistic\", \"Random-Forest\", \"SVM\", \"Gradient Boosting\", \"DNN\"]\n",
    "data = {'Models':models, 'Accuracy':all_accuracy}\n",
    "dfg = pd.DataFrame(data, columns=['Models',\"Accuracy\"])\n",
    "display(dfg.style.apply(lambda x: ['background: lightblue' if i == max(dfg[\"Accuracy\"]) else '' for i in dfg[\"Accuracy\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train.to_csv('x_train.csv')\n",
    "# y_train.to_csv('y_train.csv')\n",
    "# x_test.to_csv('x_test.csv')\n",
    "# y_test.to_csv('y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing all the models on the test dataset.\n",
    "x_train = pd.read_csv('x_train.csv', index_col=0)\n",
    "y_train = pd.read_csv('y_train.csv', index_col=0)\n",
    "x_test = pd.read_csv('x_test.csv', index_col=0)\n",
    "y_test = pd.read_csv('y_test.csv', index_col=0)\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "with open(\"svc.pkl\", 'rb') as file:\n",
    "    pickle_model_svc = pickle.load(file)\n",
    "svc_ac = accuracy_score(y_test, pickle_model_svc.predict(x_test))\n",
    "svc_precision = precision_score(y_test, pickle_model_svc.predict(x_test))\n",
    "svc_recall = recall_score(y_test, pickle_model_svc.predict(x_test))\n",
    "svc_f1 = f1_score(y_test, pickle_model_svc.predict(x_test))\n",
    "svc_fpr, svc_tpr, svc_thresholds = roc_curve(y_test, pickle_model_svc.predict(x_test)) \n",
    "svc_auc = auc(svc_fpr, svc_tpr)\n",
    "                          \n",
    "\n",
    "with open(\"rf.pkl\", 'rb') as file:\n",
    "    pickle_model_rf = pickle.load(file)\n",
    "\n",
    "with open(\"lr.pkl\", 'rb') as file:\n",
    "    pickle_model_lr = pickle.load(file)\n",
    "lr_ac = accuracy_score(y_test, pickle_model_lr.predict(x_test))\n",
    "lr_precision = precision_score(y_test, pickle_model_lr.predict(x_test))\n",
    "lr_recall = recall_score(y_test, pickle_model_lr.predict(x_test))\n",
    "lr_f1 = f1_score(y_test, pickle_model_lr.predict(x_test))\n",
    "lr_fpr, lr_tpr, lr_thresholds = roc_curve(y_test, pickle_model_lr.predict(x_test)) \n",
    "lr_auc = auc(lr_fpr, lr_tpr)\n",
    "\n",
    "with open(\"gb.pkl\", 'rb') as file:\n",
    "    pickle_model_gb = pickle.load(file)\n",
    "gb_ac = accuracy_score(y_test, pickle_model_gb.predict(x_test))\n",
    "gb_precision = precision_score(y_test, pickle_model_gb.predict(x_test))\n",
    "gb_recall = recall_score(y_test, pickle_model_gb.predict(x_test))\n",
    "gb_f1 = f1_score(y_test, pickle_model_gb.predict(x_test))\n",
    "gb_fpr, gb_tpr, gb_thresholds = roc_curve(y_test, pickle_model_gb.predict(x_test)) \n",
    "gb_auc = auc(gb_fpr, gb_tpr)\n",
    "\n",
    "with open(\"dt.pkl\", 'rb') as file:\n",
    "    pickle_model_dt = pickle.load(file)\n",
    "dt_ac = accuracy_score(y_test, pickle_model_dt.predict(x_test))\n",
    "dt_precision = precision_score(y_test, pickle_model_dt.predict(x_test))\n",
    "dt_recall = recall_score(y_test, pickle_model_dt.predict(x_test))\n",
    "dt_f1 = f1_score(y_test, pickle_model_dt.predict(x_test))\n",
    "dt_fpr, dt_tpr, dt_thresholds = roc_curve(y_test, pickle_model_dt.predict(x_test)) \n",
    "dt_auc = auc(dt_fpr, dt_tpr)\n",
    "\n",
    "with open(\"knn.pkl\", 'rb') as file:\n",
    "    pickle_model_knn = pickle.load(file)\n",
    "knn_ac = accuracy_score(y_test, pickle_model_knn.predict(x_test))\n",
    "knn_precision = precision_score(y_test, pickle_model_knn.predict(x_test))\n",
    "knn_recall = recall_score(y_test, pickle_model_knn.predict(x_test))\n",
    "knn_f1 = f1_score(y_test, pickle_model_knn.predict(x_test))\n",
    "knn_fpr, knn_tpr, knn_thresholds = roc_curve(y_test, pickle_model_knn.predict(x_test)) \n",
    "knn_auc = auc(knn_fpr, knn_tpr)\n",
    "\n",
    "dnn_model = load_model('dnn.h5')\n",
    "dnn_pred = dnn_model.predict_classes(x_test)\n",
    "dnn_ac = accuracy_score(y_test, dnn_pred)\n",
    "dnn_precision = precision_score(y_test, dnn_pred)\n",
    "dnn_recall = recall_score(y_test, dnn_pred)\n",
    "dnn_f1 = f1_score(y_test, dnn_pred)\n",
    "dnn_fpr, dnn_tpr, dnn_thresholds = roc_curve(y_test, dnn_pred) \n",
    "dnn_auc = auc(dnn_fpr, dnn_tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col0 {\n",
       "            background:  lightblue;\n",
       "        }    #T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col1 {\n",
       "            background:  lightblue;\n",
       "        }    #T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col2 {\n",
       "            background:  lightblue;\n",
       "        }    #T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col3 {\n",
       "            background:  lightblue;\n",
       "        }    #T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col4 {\n",
       "            background:  lightblue;\n",
       "        }    #T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col5 {\n",
       "            background:  lightblue;\n",
       "        }</style><table id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Models</th>        <th class=\"col_heading level0 col1\" >Accuracy</th>        <th class=\"col_heading level0 col2\" >Precision</th>        <th class=\"col_heading level0 col3\" >Recall</th>        <th class=\"col_heading level0 col4\" >F1</th>        <th class=\"col_heading level0 col5\" >AUC</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row0_col0\" class=\"data row0 col0\" >DNN</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row0_col1\" class=\"data row0 col1\" >0.941176</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row0_col2\" class=\"data row0 col2\" >0.941423</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row0_col3\" class=\"data row0 col3\" >0.941423</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row0_col4\" class=\"data row0 col4\" >0.941423</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row0_col5\" class=\"data row0 col5\" >0.941175</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row1_col0\" class=\"data row1 col0\" >Decision-Tree</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row1_col1\" class=\"data row1 col1\" >0.943277</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row1_col2\" class=\"data row1 col2\" >0.956897</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row1_col3\" class=\"data row1 col3\" >0.928870</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row1_col4\" class=\"data row1 col4\" >0.942675</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row1_col5\" class=\"data row1 col5\" >0.943338</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row2_col0\" class=\"data row2 col0\" >Gradient Boosting</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row2_col1\" class=\"data row2 col1\" >0.911765</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row2_col2\" class=\"data row2 col2\" >0.902041</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row2_col3\" class=\"data row2 col3\" >0.924686</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row2_col4\" class=\"data row2 col4\" >0.913223</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row2_col5\" class=\"data row2 col5\" >0.911710</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row3_col0\" class=\"data row3 col0\" >KNN</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row3_col1\" class=\"data row3 col1\" >0.915966</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row3_col2\" class=\"data row3 col2\" >0.909465</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row3_col3\" class=\"data row3 col3\" >0.924686</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row3_col4\" class=\"data row3 col4\" >0.917012</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row3_col5\" class=\"data row3 col5\" >0.915930</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row4_col0\" class=\"data row4 col0\" >Logistic Regression</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row4_col1\" class=\"data row4 col1\" >0.907563</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row4_col2\" class=\"data row4 col2\" >0.907950</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row4_col3\" class=\"data row4 col3\" >0.907950</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row4_col4\" class=\"data row4 col4\" >0.907950</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row4_col5\" class=\"data row4 col5\" >0.907561</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col0\" class=\"data row5 col0\" >Random-Forest</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col1\" class=\"data row5 col1\" >0.993697</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col2\" class=\"data row5 col2\" >0.995798</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col3\" class=\"data row5 col3\" >0.991632</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col4\" class=\"data row5 col4\" >0.993711</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row5_col5\" class=\"data row5 col5\" >0.993706</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row6_col0\" class=\"data row6 col0\" >SVM</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row6_col1\" class=\"data row6 col1\" >0.928571</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row6_col2\" class=\"data row6 col2\" >0.925311</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row6_col3\" class=\"data row6 col3\" >0.933054</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row6_col4\" class=\"data row6 col4\" >0.929167</td>\n",
       "                        <td id=\"T_5a82412a_7855_11eb_a21a_9931c022a3b9row6_col5\" class=\"data row6 col5\" >0.928553</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1dd9dc6e820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the results of all the models in tabular form.\n",
    "# Here, 'AUC' is considered as metric for model evaluation.\n",
    "all_accuracy = [dnn_ac, dt_ac, gb_ac, knn_ac, lr_ac, rf_ac, svc_ac]\n",
    "all_precision = [dnn_precision, dt_precision, gb_precision, knn_precision, lr_precision, rf_precision, svc_precision]\n",
    "all_recall = [dnn_recall, dt_recall, gb_recall, knn_recall, lr_recall, rf_recall, svc_recall]\n",
    "all_f1 = [dnn_f1, dt_f1, gb_f1, knn_f1, lr_f1, rf_f1, svc_f1]\n",
    "all_auc = [dnn_auc, dt_auc, gb_auc, knn_auc, lr_auc, rf_auc, svc_auc]\n",
    "models = [\"DNN\", \"Decision-Tree\", \"Gradient Boosting\", \"KNN\", \"Logistic Regression\", \"Random-Forest\", \"SVM\"]\n",
    "data = {'Models':models, 'Accuracy':all_accuracy, \"Precision\":all_precision, \"Recall\":all_recall, \"F1\":all_f1, \"AUC\":all_auc}\n",
    "dfg = pd.DataFrame(data, columns=['Models',\"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"AUC\"])\n",
    "display(dfg.style.apply(lambda x: ['background: lightblue' if i == max(dfg[\"Accuracy\"]) else '' for i in dfg[\"Accuracy\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
